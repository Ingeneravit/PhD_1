{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from pythonosc import udp_client\n",
    "\n",
    "epoch_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "(100, 32, 32, 3)\n",
      "x_train shape: (50000, 32, 32, 3, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "x_c1 = x_train[(y_train == 1)[:,0]][:50].reshape(50, -1)\n",
    "x_c9 = x_train[(y_train == 9)[:,0]][:50].reshape(50, -1)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "x_100 = np.concatenate([x_train[(y_train == 1)[:,0]][:50], x_train[(y_train == 9)[:,0]][:50]])\n",
    "print((x_100).shape)\n",
    "\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\ttrain_norm = train.astype('float32') / 255\n",
    "\ttest_norm = test.astype('float32') / 255\n",
    "\n",
    "\treturn train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                81940     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147718 (577.02 KB)\n",
      "Trainable params: 147718 (577.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),  \n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer='he_uniform', padding='same'),  \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer='he_uniform', padding='same'),  \n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer='he_uniform', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(20, activation=\"relu\", kernel_initializer='he_uniform'),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class outs1(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, epoch, logs=None):\n",
    "        global epoch_step\n",
    "        epoch_step = 1\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global epoch_step\n",
    "        epoch_step += 1\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):          \n",
    "        \n",
    "        from keras import backend as K\n",
    "        from IPython.display import clear_output\n",
    "        #clear_output(wait=True)\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            clear_output(wait=True)\n",
    "            fig, axes = plt.subplots(1,5)\n",
    "\n",
    "\n",
    "            inp = model.input\n",
    "            outputs = [layer.output for layer in model.layers]\n",
    "            functors = [K.function([inp], [out]) for out in outputs]\n",
    "            \n",
    "            test = np.random.random(input_shape)[np.newaxis,...]\n",
    "            \n",
    "            layer_outs_1 = [func([x_test[0][np.newaxis,...]]) for func in functors]\n",
    "            layer_outs_2 = [func(x_100) for func in functors]\n",
    "            \n",
    "\n",
    "            #x_100_flattened = layer_outs_2[7][0][:,:,:,:].reshape(100,-1)\n",
    "            x_100_flattened = layer_outs_2[-2][0]\n",
    "            metric = np.zeros((100, 100))\n",
    "            for i in range(100):\n",
    "                for j in range(100):\n",
    "                    metric[i,j] = np.linalg.norm(x_100_flattened[i] - x_100_flattened[j])\n",
    "\n",
    "                    #metric[i,j] = np.dot(x_100_flattened[i], x_100_flattened[j])\n",
    "            \n",
    "            #print(layer_outs_2[7][0].shape)\n",
    "            x_100_flattened_2 = layer_outs_2[-1][0]\n",
    "            #x_100_flattened_2 = layer_outs_2[7][0][:,:,:,:].reshape(100,-1)\n",
    "            metric_2 = np.zeros((100, 100))\n",
    "            for i in range(100):\n",
    "                for j in range(100):\n",
    "                    metric_2[i,j] = np.linalg.norm(x_100_flattened_2[i] - x_100_flattened_2[j])\n",
    "            \n",
    "            \n",
    "            a = np.sum(metric_2[:50,:50]) / 50**2\n",
    "            b = np.sum(metric_2[:50,50:]) / 50**2\n",
    "            c = np.sum(metric_2[50:,:50]) / 50**2\n",
    "            d = np.sum(metric_2[50:,50:]) / 50**2\n",
    "\n",
    "            e = b - a\n",
    "            f = c - d\n",
    "\n",
    "            print('\\n', e, f)\n",
    "\n",
    "            x_100_flattened_3 = layer_outs_2[0][0]\n",
    "            metric_3 = np.zeros((100, 100))\n",
    "            for i in range(100):\n",
    "                for j in range(100):\n",
    "                    metric_3[i,j] = np.linalg.norm(x_100_flattened_3[i] - x_100_flattened_3[j])\n",
    "            \n",
    "\n",
    "            axes[0].imshow(x_test[0], cmap='viridis')\n",
    "            axes[1].imshow(layer_outs_1[0][0][0,:,:,0], cmap='viridis')\n",
    "            axes[2].imshow(metric, cmap='viridis')\n",
    "            axes[3].imshow(metric_2, cmap='viridis')\n",
    "            axes[4].imshow(metric_3, cmap='viridis')\n",
    "            \n",
    "            # for x in range (5):\n",
    "            #     axes[x].set_xticks([])\n",
    "            #     axes[x].set_yticks([])  \n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            #print(np.sum(np.argmax(layer_outs_2[8][0][:50], axis=1) == 1), np.sum(np.argmax(layer_outs_2[8][0][50:], axis=1) == 9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5417067350083031 0.5610468766149134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam()\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/engine/training.py:1813\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1812\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1813\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/callbacks.py:771\u001b[0m, in \u001b[0;36mCallback.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a training batch in `fit` methods.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03mSubclasses should override for any actions to run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# For backwards compatibility.\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 64\u001b[0m, in \u001b[0;36mouts1.on_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m         metric_3[i,j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_100_flattened_3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_100_flattened_3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(x_test[\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(layer_outs_1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m,:,:,\u001b[38;5;241m0\u001b[39m], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/linalg/linalg.py:2552\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2550\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x_real\u001b[38;5;241m.\u001b[39mdot(x_real) \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[1;32m   2551\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2552\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2553\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks_list = [outs1()]\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test), verbose=1, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
