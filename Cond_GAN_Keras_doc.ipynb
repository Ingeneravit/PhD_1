{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from tensorflow_docs.vis import embed\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (70000, 28, 28, 1)\n",
      "Shape of training labels: (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_digits.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 11\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"generator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"generator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6762</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,918</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6762</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">282,752</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,273</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6762\u001b[0m)           │       \u001b[38;5;34m939,918\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_12 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6762\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m138\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m282,752\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_13 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_14 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │         \u001b[38;5;34m6,273\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,491,215</span> (5.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,491,215\u001b[0m (5.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,491,215</span> (5.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,491,215\u001b[0m (5.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator summary: None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m6,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_10 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_11 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,385</span> (314.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m80,385\u001b[0m (314.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,385</span> (314.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,385\u001b[0m (314.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator summary: None\n"
     ]
    }
   ],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(7 * 7 * generator_in_channels),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Reshape((7, 7, generator_in_channels)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(negative_slope=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "print(\"Generator summary:\", generator.summary())\n",
    "print(\"Discriminator summary:\", discriminator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = ops.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = ops.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = ops.shape(real_images)[0]\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = ops.concatenate(\n",
    "            [generated_images, image_one_hot_labels], -1\n",
    "        )\n",
    "        real_image_and_labels = ops.concatenate([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = ops.concatenate(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = ops.concatenate(\n",
    "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "        random_vector_labels = ops.concatenate(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = ops.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = ops.concatenate(\n",
    "                [fake_images, image_one_hot_labels], -1\n",
    "            )\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class outs1(keras.callbacks.Callback):\n",
    "\n",
    "#     def on_batch_end(self, batch, logs={}):          \n",
    "               \n",
    "#         from keras import backend as K\n",
    "#         from IPython.display import clear_output\n",
    "\n",
    "#         if batch % 20 == 0:\n",
    "#             clear_output(wait=True)\n",
    "\n",
    "#             fig, axes = plt.subplots(12,4)\n",
    "\n",
    "#             inp = self.model.discriminator.inputs\n",
    "#             outputs = [layer.output for layer in self.model.discriminator.layers]\n",
    "\n",
    "#             functors = [K.function([inp], [out]) for out in outputs]           \n",
    "            \n",
    "#             for i in range(12):\n",
    "#                 layer_outs_1 = [func([x_test[i][np.newaxis,...]]) for func in functors]\n",
    "\n",
    "#                 axes[i,0].imshow(x_test[i], cmap='viridis')\n",
    "#                 axes[i,1].imshow(layer_outs_1[1][0][0,:,:,0], cmap='viridis')\n",
    "#                 axes[i,2].imshow(layer_outs_1[3][0][0,:,:,0], cmap='viridis')\n",
    "#                 axes[i,3].imshow(layer_outs_1[-1][0][:,:], cmap='viridis')\n",
    "\n",
    "            \n",
    "#             for i in range(12):\n",
    "#                 for j in range(5):\n",
    "#                     axes[i,j].axis('off')\n",
    "#                     axes[i,j].set_xticks([])\n",
    "#                     axes[i,j].set_yticks([])\n",
    "\n",
    "#             fig.set_figheight(15)\n",
    "#             fig.set_figwidth(8)\n",
    "\n",
    "           \n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class outs1(keras.callbacks.Callback):\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):          \n",
    "\n",
    "        y_train_reshaped = keras.utils.to_categorical(y_train[0], 10)\n",
    "        print(y_train_reshaped.shape)\n",
    "\n",
    "        y_reshaped_2 = y_train_reshaped[None, :, None, None]\n",
    "        y_reshaped_2 = ops.repeat(\n",
    "            y_reshaped_2, repeats=[image_size * image_size]\n",
    "        )\n",
    "        y_reshaped_2 = ops.reshape(\n",
    "            y_reshaped_2, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "        \n",
    "        x_train_2 = x_train[0][None, :, :, None]\n",
    "\n",
    "        if batch % 20 == 1:\n",
    "            new_array = np.concatenate([x_train_2, y_reshaped_2], axis=3)                    \n",
    "            pred_outputs = self.model.discriminator.predict(new_array), discriminator_in_channels\n",
    "\n",
    "            print(pred_outputs)\n",
    "\n",
    "            test_1 = self.model.discriminator.layers[0](new_array)\n",
    "            plt.imsave('/Users/user/Library/CloudStorage/OneDrive-Personal/Mac/PhD/Spect2/img_{0}_0.png'.format(batch), test_1[0, :, :, 0], cmap='viridis')\n",
    "            print(test_1.shape)\n",
    "            test_2 = self.model.discriminator.layers[1](test_1)\n",
    "            plt.imsave('/Users/user/Library/CloudStorage/OneDrive-Personal/Mac/PhD/Spect2/img_{0}_1.png'.format(batch), test_2[0, :, :, 0], cmap='viridis')\n",
    "            print(test_2.shape)\n",
    "            test_3 = self.model.discriminator.layers[2](test_2)\n",
    "            plt.imsave('/Users/user/Library/CloudStorage/OneDrive-Personal/Mac/PhD/Spect2/img_{0}_2.png'.format(batch), test_3[0, :, :, 0], cmap='viridis')\n",
    "            print(test_3.shape)\n",
    "            test_4 = self.model.discriminator.layers[3](test_3)\n",
    "            plt.imsave('/Users/user/Library/CloudStorage/OneDrive-Personal/Mac/PhD/Spect2/img_{0}_3.png'.format(batch), test_4[0, :, :, 0], cmap='viridis')\n",
    "            print(test_4.shape)\n",
    "            test_5 = self.model.discriminator.layers[4](test_4)\n",
    "            print(test_5.shape)\n",
    "            test_6 = self.model.discriminator.layers[5](test_5)\n",
    "            # plt.imsave('/Users/user/Library/CloudStorage/OneDrive-Personal/Mac/PhD/Spect2/img_{0}_3.png'.format(batch), test_6[0, :], cmap='viridis')\n",
    "            print(test_6.shape)\n",
    "\n",
    "            # from keras.models import Model\n",
    "\n",
    "            # layer_name = 'conv2d_transpose_2'\n",
    "            # intermediate_layer_model = Model(inputs=self.model.input,\n",
    "            #                      outputs=self.model.generator.get_layer(layer_name).output)\n",
    "            # intermediate_output = intermediate_layer_model.predict(x_train[0][None, :, :, None])\n",
    "\n",
    "            # # show image of intermediate output\n",
    "            # plt.imshow(intermediate_output[0, :, :, 0], cmap='viridis')\n",
    "\n",
    "            # plt.imsave('/Users/user/Library/CloudStorage/OneDrive-Personal/Mac/PhD/Spect2/img.png', pred_outputs[-1], cmap='viridis')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class outs2(keras.callbacks.Callback):\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):          \n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss_d = logs.get('d_loss')\n",
    "            loss_g = logs.get('g_loss')\n",
    "\n",
    "            print('\\nLoss discriminator: {0}, Loss generator: {1}'.format(loss_d, loss_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Loss discriminator: 0.6914664506912231, Loss generator: 0.6105341911315918\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:14\u001b[0m 181ms/step - d_loss: 0.6682 - g_loss: 0.6934\n",
      "Loss discriminator: 0.6605565547943115, Loss generator: 0.7167260646820068\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 179ms/step - d_loss: 0.6666 - g_loss: 0.7054\n",
      "Loss discriminator: 0.6637739539146423, Loss generator: 0.7239927649497986\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 179ms/step - d_loss: 0.6633 - g_loss: 0.7142\n",
      "Loss discriminator: 0.6464548707008362, Loss generator: 0.744534432888031\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 178ms/step - d_loss: 0.6560 - g_loss: 0.7254\n",
      "Loss discriminator: 0.6194649338722229, Loss generator: 0.777538537979126\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 178ms/step - d_loss: 0.6456 - g_loss: 0.7400\n",
      "Loss discriminator: 0.5872973799705505, Loss generator: 0.820364773273468\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 178ms/step - d_loss: 0.6364 - g_loss: 0.7517\n",
      "Loss discriminator: 0.6065781712532043, Loss generator: 0.7914831042289734\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 178ms/step - d_loss: 0.6322 - g_loss: 0.7591\n",
      "Loss discriminator: 0.5970369577407837, Loss generator: 0.8242362141609192\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 179ms/step - d_loss: 0.6255 - g_loss: 0.7722\n",
      "Loss discriminator: 0.5559780597686768, Loss generator: 0.9145416021347046\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 179ms/step - d_loss: 0.6164 - g_loss: 0.7903\n",
      "Loss discriminator: 0.5395216345787048, Loss generator: 0.9440573453903198\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 179ms/step - d_loss: 0.6089 - g_loss: 0.8052\n",
      "Loss discriminator: 0.5416213274002075, Loss generator: 0.9362771511077881\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 180ms/step - d_loss: 0.6028 - g_loss: 0.8171\n",
      "Loss discriminator: 0.5424931645393372, Loss generator: 0.9360278248786926\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 181ms/step - d_loss: 0.5978 - g_loss: 0.8269\n",
      "Loss discriminator: 0.5428245663642883, Loss generator: 0.9334191083908081\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 181ms/step - d_loss: 0.5935 - g_loss: 0.8351\n",
      "Loss discriminator: 0.5404647588729858, Loss generator: 0.9337729811668396\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 181ms/step - d_loss: 0.5896 - g_loss: 0.8423\n",
      "Loss discriminator: 0.5354437828063965, Loss generator: 0.9400590062141418\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 181ms/step - d_loss: 0.5857 - g_loss: 0.8491\n",
      "Loss discriminator: 0.5281708836555481, Loss generator: 0.9499637484550476\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 181ms/step - d_loss: 0.5819 - g_loss: 0.8558\n",
      "Loss discriminator: 0.5207372903823853, Loss generator: 0.9621137976646423\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 181ms/step - d_loss: 0.5781 - g_loss: 0.8623\n",
      "Loss discriminator: 0.5156071782112122, Loss generator: 0.9719946980476379\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 181ms/step - d_loss: 0.5746 - g_loss: 0.8686\n",
      "Loss discriminator: 0.5137129426002502, Loss generator: 0.9785751104354858\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 181ms/step - d_loss: 0.5714 - g_loss: 0.8745\n",
      "Loss discriminator: 0.5134015679359436, Loss generator: 0.9808997511863708\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 181ms/step - d_loss: 0.5686 - g_loss: 0.8797\n",
      "Loss discriminator: 0.5166985988616943, Loss generator: 0.9746858477592468\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 181ms/step - d_loss: 0.5661 - g_loss: 0.8841\n",
      "Loss discriminator: 0.5180909633636475, Loss generator: 0.971279501914978\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 184ms/step - d_loss: 0.5640 - g_loss: 0.8880\n",
      "Loss discriminator: 0.5182291269302368, Loss generator: 0.9696468710899353\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 187ms/step - d_loss: 0.5620 - g_loss: 0.8916\n",
      "Loss discriminator: 0.5171759128570557, Loss generator: 0.9701868891716003\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 189ms/step - d_loss: 0.5601 - g_loss: 0.8949\n",
      "Loss discriminator: 0.5154410004615784, Loss generator: 0.9721712470054626\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 192ms/step - d_loss: 0.5582 - g_loss: 0.8981\n",
      "Loss discriminator: 0.5122600197792053, Loss generator: 0.9772969484329224\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 194ms/step - d_loss: 0.5564 - g_loss: 0.9012\n",
      "Loss discriminator: 0.5121523141860962, Loss generator: 0.9789929986000061\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 196ms/step - d_loss: 0.5548 - g_loss: 0.9040\n",
      "Loss discriminator: 0.5142000913619995, Loss generator: 0.9774598479270935\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 198ms/step - d_loss: 0.5534 - g_loss: 0.9066\n",
      "Loss discriminator: 0.5159538984298706, Loss generator: 0.9753074049949646\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 199ms/step - d_loss: 0.5521 - g_loss: 0.9089\n",
      "Loss discriminator: 0.5173208117485046, Loss generator: 0.9731266498565674\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 201ms/step - d_loss: 0.5510 - g_loss: 0.9111\n",
      "Loss discriminator: 0.518403172492981, Loss generator: 0.9717329144477844\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 203ms/step - d_loss: 0.5500 - g_loss: 0.9130\n",
      "Loss discriminator: 0.5189661383628845, Loss generator: 0.9703813195228577\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 204ms/step - d_loss: 0.5490 - g_loss: 0.9148\n",
      "Loss discriminator: 0.5195828676223755, Loss generator: 0.9694020748138428\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 205ms/step - d_loss: 0.5481 - g_loss: 0.9164\n",
      "Loss discriminator: 0.52060467004776, Loss generator: 0.9676588177680969\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 207ms/step - d_loss: 0.5473 - g_loss: 0.9179\n",
      "Loss discriminator: 0.5225396156311035, Loss generator: 0.9644331932067871\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 208ms/step - d_loss: 0.5466 - g_loss: 0.9192\n",
      "Loss discriminator: 0.523431122303009, Loss generator: 0.9627307653427124\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 209ms/step - d_loss: 0.5460 - g_loss: 0.9204\n",
      "Loss discriminator: 0.5243496894836426, Loss generator: 0.9609290957450867\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 210ms/step - d_loss: 0.5454 - g_loss: 0.9214\n",
      "Loss discriminator: 0.525021493434906, Loss generator: 0.9593570232391357\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 211ms/step - d_loss: 0.5449 - g_loss: 0.9224\n",
      "Loss discriminator: 0.52593594789505, Loss generator: 0.9588080048561096\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 212ms/step - d_loss: 0.5444 - g_loss: 0.9233\n",
      "Loss discriminator: 0.527630090713501, Loss generator: 0.9568318724632263\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 213ms/step - d_loss: 0.5440 - g_loss: 0.9241\n",
      "Loss discriminator: 0.529269814491272, Loss generator: 0.9546788334846497\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 213ms/step - d_loss: 0.5437 - g_loss: 0.9249\n",
      "Loss discriminator: 0.5316751003265381, Loss generator: 0.9513753652572632\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m54s\u001b[0m 214ms/step - d_loss: 0.5434 - g_loss: 0.9254\n",
      "Loss discriminator: 0.5340554118156433, Loss generator: 0.9476699829101562\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m50s\u001b[0m 215ms/step - d_loss: 0.5432 - g_loss: 0.9259\n",
      "Loss discriminator: 0.5360586643218994, Loss generator: 0.9443992972373962\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m46s\u001b[0m 215ms/step - d_loss: 0.5431 - g_loss: 0.9263\n",
      "Loss discriminator: 0.5377442836761475, Loss generator: 0.9414049983024597\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41s\u001b[0m 216ms/step - d_loss: 0.5430 - g_loss: 0.9266\n",
      "Loss discriminator: 0.5392006635665894, Loss generator: 0.9390679001808167\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 217ms/step - d_loss: 0.5429 - g_loss: 0.9269\n",
      "Loss discriminator: 0.540221631526947, Loss generator: 0.9373778700828552\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m33s\u001b[0m 218ms/step - d_loss: 0.5429 - g_loss: 0.9271\n",
      "Loss discriminator: 0.541609525680542, Loss generator: 0.935133695602417\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m29s\u001b[0m 218ms/step - d_loss: 0.5429 - g_loss: 0.9272\n",
      "Loss discriminator: 0.5431762933731079, Loss generator: 0.9326445460319519\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 219ms/step - d_loss: 0.5429 - g_loss: 0.9273\n",
      "Loss discriminator: 0.5446314811706543, Loss generator: 0.9303898215293884\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 219ms/step - d_loss: 0.5429 - g_loss: 0.9273\n",
      "Loss discriminator: 0.5458256602287292, Loss generator: 0.9283479452133179\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 220ms/step - d_loss: 0.5430 - g_loss: 0.9273\n",
      "Loss discriminator: 0.5467148423194885, Loss generator: 0.9268133044242859\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - d_loss: 0.5431 - g_loss: 0.9273\n",
      "Loss discriminator: 0.5476774573326111, Loss generator: 0.9249750971794128\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - d_loss: 0.5432 - g_loss: 0.9273\n",
      "Loss discriminator: 0.5489464402198792, Loss generator: 0.9232308268547058\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - d_loss: 0.5433 - g_loss: 0.9272\n",
      "Loss discriminator: 0.5492063164710999, Loss generator: 0.9229714870452881\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 222ms/step - d_loss: 0.5434 - g_loss: 0.9271 - discriminator_loss: 0.5499 - generator_loss: 0.9220\n",
      "Epoch 2/20\n",
      "\n",
      "Loss discriminator: 0.6037881374359131, Loss generator: 0.7881835103034973\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 250ms/step - d_loss: 0.6356 - g_loss: 0.8054\n",
      "Loss discriminator: 0.6409815549850464, Loss generator: 0.8035089373588562\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:20\u001b[0m 247ms/step - d_loss: 0.6363 - g_loss: 0.8052\n",
      "Loss discriminator: 0.6331256031990051, Loss generator: 0.8069128394126892\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:16\u001b[0m 248ms/step - d_loss: 0.6332 - g_loss: 0.8083\n",
      "Loss discriminator: 0.6194024682044983, Loss generator: 0.8219884634017944\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:11\u001b[0m 248ms/step - d_loss: 0.6284 - g_loss: 0.8129\n",
      "Loss discriminator: 0.6113206148147583, Loss generator: 0.8297688961029053\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 249ms/step - d_loss: 0.6250 - g_loss: 0.8169\n",
      "Loss discriminator: 0.6125470995903015, Loss generator: 0.8324499130249023\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:01\u001b[0m 248ms/step - d_loss: 0.6235 - g_loss: 0.8192\n",
      "Loss discriminator: 0.6187374591827393, Loss generator: 0.8316976428031921\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 249ms/step - d_loss: 0.6230 - g_loss: 0.8207\n",
      "Loss discriminator: 0.6173998713493347, Loss generator: 0.8327300548553467\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 249ms/step - d_loss: 0.6221 - g_loss: 0.8228\n",
      "Loss discriminator: 0.6115766763687134, Loss generator: 0.847327470779419\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 248ms/step - d_loss: 0.6208 - g_loss: 0.8257\n",
      "Loss discriminator: 0.6099299192428589, Loss generator: 0.8502858281135559\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:41\u001b[0m 248ms/step - d_loss: 0.6198 - g_loss: 0.8280\n",
      "Loss discriminator: 0.612361490726471, Loss generator: 0.8471135497093201\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 247ms/step - d_loss: 0.6193 - g_loss: 0.8296\n",
      "Loss discriminator: 0.6174116134643555, Loss generator: 0.8405243754386902\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 247ms/step - d_loss: 0.6193 - g_loss: 0.8302\n",
      "Loss discriminator: 0.6212533116340637, Loss generator: 0.8347461819648743\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:26\u001b[0m 247ms/step - d_loss: 0.6195 - g_loss: 0.8305\n",
      "Loss discriminator: 0.6213756799697876, Loss generator: 0.8333420157432556\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 247ms/step - d_loss: 0.6196 - g_loss: 0.8307\n",
      "Loss discriminator: 0.6205413937568665, Loss generator: 0.8332545161247253\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 247ms/step - d_loss: 0.6197 - g_loss: 0.8309\n",
      "Loss discriminator: 0.6211894154548645, Loss generator: 0.8322911858558655\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 246ms/step - d_loss: 0.6198 - g_loss: 0.8309\n",
      "Loss discriminator: 0.6230229735374451, Loss generator: 0.8289421200752258\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 246ms/step - d_loss: 0.6201 - g_loss: 0.8307\n",
      "Loss discriminator: 0.6252870559692383, Loss generator: 0.8256630897521973\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 246ms/step - d_loss: 0.6204 - g_loss: 0.8303\n",
      "Loss discriminator: 0.6271620392799377, Loss generator: 0.8221014738082886\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 246ms/step - d_loss: 0.6208 - g_loss: 0.8298\n",
      "Loss discriminator: 0.6277970671653748, Loss generator: 0.8217854499816895\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 245ms/step - d_loss: 0.6211 - g_loss: 0.8295\n",
      "Loss discriminator: 0.6274968981742859, Loss generator: 0.8226441740989685\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 246ms/step - d_loss: 0.6214 - g_loss: 0.8292\n",
      "Loss discriminator: 0.6267091035842896, Loss generator: 0.824607789516449\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 246ms/step - d_loss: 0.6216 - g_loss: 0.8290\n",
      "Loss discriminator: 0.6262646913528442, Loss generator: 0.8274281024932861\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 246ms/step - d_loss: 0.6219 - g_loss: 0.8290\n",
      "Loss discriminator: 0.628374457359314, Loss generator: 0.8264355063438416\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 246ms/step - d_loss: 0.6221 - g_loss: 0.8289\n",
      "Loss discriminator: 0.6278692483901978, Loss generator: 0.827669620513916\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 246ms/step - d_loss: 0.6224 - g_loss: 0.8288\n",
      "Loss discriminator: 0.6294413208961487, Loss generator: 0.8264932632446289\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 246ms/step - d_loss: 0.6226 - g_loss: 0.8287\n",
      "Loss discriminator: 0.6293805837631226, Loss generator: 0.8273075819015503\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 245ms/step - d_loss: 0.6229 - g_loss: 0.8287\n",
      "Loss discriminator: 0.6289691925048828, Loss generator: 0.8271667957305908\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 245ms/step - d_loss: 0.6231 - g_loss: 0.8286\n",
      "Loss discriminator: 0.6310169100761414, Loss generator: 0.824996292591095\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 245ms/step - d_loss: 0.6234 - g_loss: 0.8285\n",
      "Loss discriminator: 0.6306546926498413, Loss generator: 0.8256474137306213\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 245ms/step - d_loss: 0.6236 - g_loss: 0.8284\n",
      "Loss discriminator: 0.6309035420417786, Loss generator: 0.8257986307144165\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 245ms/step - d_loss: 0.6239 - g_loss: 0.8283\n",
      "Loss discriminator: 0.6313871145248413, Loss generator: 0.824463963508606\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 245ms/step - d_loss: 0.6241 - g_loss: 0.8281\n",
      "Loss discriminator: 0.6322742104530334, Loss generator: 0.823654294013977\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 245ms/step - d_loss: 0.6244 - g_loss: 0.8280\n",
      "Loss discriminator: 0.6332215070724487, Loss generator: 0.8224658370018005\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 245ms/step - d_loss: 0.6246 - g_loss: 0.8279\n",
      "Loss discriminator: 0.6310791373252869, Loss generator: 0.8253952860832214\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 245ms/step - d_loss: 0.6248 - g_loss: 0.8278\n",
      "Loss discriminator: 0.6323674917221069, Loss generator: 0.8237413763999939\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 245ms/step - d_loss: 0.6250 - g_loss: 0.8277\n",
      "Loss discriminator: 0.6307617425918579, Loss generator: 0.8254386186599731\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 245ms/step - d_loss: 0.6252 - g_loss: 0.8276\n",
      "Loss discriminator: 0.6322240233421326, Loss generator: 0.8240731358528137\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 246ms/step - d_loss: 0.6254 - g_loss: 0.8275\n",
      "Loss discriminator: 0.6321508288383484, Loss generator: 0.8240518569946289\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 245ms/step - d_loss: 0.6255 - g_loss: 0.8274\n",
      "Loss discriminator: 0.6318426728248596, Loss generator: 0.8247504830360413\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 245ms/step - d_loss: 0.6257 - g_loss: 0.8273\n",
      "Loss discriminator: 0.6328558325767517, Loss generator: 0.8230371475219727\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 245ms/step - d_loss: 0.6259 - g_loss: 0.8273\n",
      "Loss discriminator: 0.6320109963417053, Loss generator: 0.8238250613212585\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 245ms/step - d_loss: 0.6260 - g_loss: 0.8272\n",
      "Loss discriminator: 0.6332570910453796, Loss generator: 0.8224027156829834\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m57s\u001b[0m 245ms/step - d_loss: 0.6262 - g_loss: 0.8271\n",
      "Loss discriminator: 0.6319924592971802, Loss generator: 0.8242995142936707\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m52s\u001b[0m 245ms/step - d_loss: 0.6263 - g_loss: 0.8270\n",
      "Loss discriminator: 0.6325626373291016, Loss generator: 0.8241329193115234\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m47s\u001b[0m 245ms/step - d_loss: 0.6265 - g_loss: 0.8269\n",
      "Loss discriminator: 0.6316002607345581, Loss generator: 0.8255242705345154\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m42s\u001b[0m 245ms/step - d_loss: 0.6266 - g_loss: 0.8270\n",
      "Loss discriminator: 0.6301344633102417, Loss generator: 0.8281773328781128\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m37s\u001b[0m 245ms/step - d_loss: 0.6267 - g_loss: 0.8270\n",
      "Loss discriminator: 0.6320381164550781, Loss generator: 0.8264554142951965\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m32s\u001b[0m 245ms/step - d_loss: 0.6268 - g_loss: 0.8270\n",
      "Loss discriminator: 0.630679726600647, Loss generator: 0.8288208246231079\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 245ms/step - d_loss: 0.6269 - g_loss: 0.8270\n",
      "Loss discriminator: 0.6327492594718933, Loss generator: 0.8270403742790222\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - d_loss: 0.6270 - g_loss: 0.8270\n",
      "Loss discriminator: 0.6324114799499512, Loss generator: 0.8277421593666077\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 245ms/step - d_loss: 0.6271 - g_loss: 0.8270\n",
      "Loss discriminator: 0.6294402480125427, Loss generator: 0.8320404887199402\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 245ms/step - d_loss: 0.6271 - g_loss: 0.8271\n",
      "Loss discriminator: 0.6301169395446777, Loss generator: 0.8314980864524841\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - d_loss: 0.6272 - g_loss: 0.8272\n",
      "Loss discriminator: 0.6310989260673523, Loss generator: 0.8306524157524109\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - d_loss: 0.6272 - g_loss: 0.8273\n",
      "Loss discriminator: 0.6319290399551392, Loss generator: 0.8298486471176147\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 245ms/step - d_loss: 0.6273 - g_loss: 0.8273 - discriminator_loss: 0.6330 - generator_loss: 0.8286\n",
      "Epoch 3/20\n",
      "\n",
      "Loss discriminator: 0.6489102840423584, Loss generator: 0.7565528750419617\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:27\u001b[0m 249ms/step - d_loss: 0.6149 - g_loss: 0.8200\n",
      "Loss discriminator: 0.5613448023796082, Loss generator: 0.8976057171821594\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 245ms/step - d_loss: 0.5787 - g_loss: 0.8749\n",
      "Loss discriminator: 0.5444241762161255, Loss generator: 0.9295864701271057\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:11\u001b[0m 243ms/step - d_loss: 0.5730 - g_loss: 0.8860\n",
      "Loss discriminator: 0.5745493173599243, Loss generator: 0.8921455144882202\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:08\u001b[0m 245ms/step - d_loss: 0.5746 - g_loss: 0.8859\n",
      "Loss discriminator: 0.585259199142456, Loss generator: 0.876001238822937\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:04\u001b[0m 246ms/step - d_loss: 0.5797 - g_loss: 0.8807\n",
      "Loss discriminator: 0.6182729601860046, Loss generator: 0.8417545557022095\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:00\u001b[0m 247ms/step - d_loss: 0.5874 - g_loss: 0.8724\n",
      "Loss discriminator: 0.6287484169006348, Loss generator: 0.825411319732666\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:54\u001b[0m 246ms/step - d_loss: 0.5932 - g_loss: 0.8660\n",
      "Loss discriminator: 0.625857949256897, Loss generator: 0.8277537822723389\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 245ms/step - d_loss: 0.5971 - g_loss: 0.8614\n",
      "Loss discriminator: 0.6232348084449768, Loss generator: 0.8309586644172668\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:43\u001b[0m 244ms/step - d_loss: 0.5998 - g_loss: 0.8584\n",
      "Loss discriminator: 0.6183103919029236, Loss generator: 0.83765709400177\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:38\u001b[0m 245ms/step - d_loss: 0.6016 - g_loss: 0.8564\n",
      "Loss discriminator: 0.6190139055252075, Loss generator: 0.8373810648918152\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34\u001b[0m 245ms/step - d_loss: 0.6034 - g_loss: 0.8543\n",
      "Loss discriminator: 0.6239105463027954, Loss generator: 0.8309341073036194\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 246ms/step - d_loss: 0.6050 - g_loss: 0.8524\n",
      "Loss discriminator: 0.6227519512176514, Loss generator: 0.8309701681137085\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 246ms/step - d_loss: 0.6065 - g_loss: 0.8506\n",
      "Loss discriminator: 0.6269493103027344, Loss generator: 0.8263025283813477\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 246ms/step - d_loss: 0.6080 - g_loss: 0.8488\n",
      "Loss discriminator: 0.6267456412315369, Loss generator: 0.8265713453292847\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 246ms/step - d_loss: 0.6092 - g_loss: 0.8475\n",
      "Loss discriminator: 0.6231675744056702, Loss generator: 0.8317840695381165\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 246ms/step - d_loss: 0.6101 - g_loss: 0.8465\n",
      "Loss discriminator: 0.6255272030830383, Loss generator: 0.8279802799224854\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 246ms/step - d_loss: 0.6109 - g_loss: 0.8455\n",
      "Loss discriminator: 0.6193442344665527, Loss generator: 0.8362953662872314\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 244ms/step - d_loss: 0.6112 - g_loss: 0.8452\n",
      "Loss discriminator: 0.6176982522010803, Loss generator: 0.8399520516395569\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 242ms/step - d_loss: 0.6117 - g_loss: 0.8448\n",
      "Loss discriminator: 0.623668372631073, Loss generator: 0.8341524004936218\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 240ms/step - d_loss: 0.6123 - g_loss: 0.8443\n",
      "Loss discriminator: 0.6215440034866333, Loss generator: 0.8390856981277466\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 238ms/step - d_loss: 0.6127 - g_loss: 0.8442\n",
      "Loss discriminator: 0.6182858347892761, Loss generator: 0.8449357748031616\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 235ms/step - d_loss: 0.6130 - g_loss: 0.8441\n",
      "Loss discriminator: 0.6239851713180542, Loss generator: 0.8388198018074036\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 232ms/step - d_loss: 0.6134 - g_loss: 0.8440\n",
      "Loss discriminator: 0.6175419688224792, Loss generator: 0.848173201084137\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 230ms/step - d_loss: 0.6135 - g_loss: 0.8443\n",
      "Loss discriminator: 0.617083728313446, Loss generator: 0.8509242534637451\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 228ms/step - d_loss: 0.6138 - g_loss: 0.8445\n",
      "Loss discriminator: 0.6198612451553345, Loss generator: 0.847791314125061\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 225ms/step - d_loss: 0.6140 - g_loss: 0.8446\n",
      "Loss discriminator: 0.6177611947059631, Loss generator: 0.8505347371101379\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 223ms/step - d_loss: 0.6141 - g_loss: 0.8449\n",
      "Loss discriminator: 0.6166445016860962, Loss generator: 0.8530051708221436\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 222ms/step - d_loss: 0.6142 - g_loss: 0.8451\n",
      "Loss discriminator: 0.6221929788589478, Loss generator: 0.8473374843597412\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 220ms/step - d_loss: 0.6145 - g_loss: 0.8452\n",
      "Loss discriminator: 0.6182639002799988, Loss generator: 0.8533024787902832\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 218ms/step - d_loss: 0.6145 - g_loss: 0.8458\n",
      "Loss discriminator: 0.6104459762573242, Loss generator: 0.8671733736991882\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 217ms/step - d_loss: 0.6144 - g_loss: 0.8464\n",
      "Loss discriminator: 0.6127964854240417, Loss generator: 0.8656409978866577\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 216ms/step - d_loss: 0.6143 - g_loss: 0.8470\n",
      "Loss discriminator: 0.6133069396018982, Loss generator: 0.8654665946960449\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 215ms/step - d_loss: 0.6143 - g_loss: 0.8476\n",
      "Loss discriminator: 0.6127550005912781, Loss generator: 0.866893470287323\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 214ms/step - d_loss: 0.6143 - g_loss: 0.8481\n",
      "Loss discriminator: 0.6156166791915894, Loss generator: 0.8633349537849426\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 212ms/step - d_loss: 0.6143 - g_loss: 0.8485\n",
      "Loss discriminator: 0.6160635948181152, Loss generator: 0.8620607256889343\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 211ms/step - d_loss: 0.6143 - g_loss: 0.8490\n",
      "Loss discriminator: 0.612637996673584, Loss generator: 0.8664836287498474\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 210ms/step - d_loss: 0.6143 - g_loss: 0.8495\n",
      "Loss discriminator: 0.6116153001785278, Loss generator: 0.8679945468902588\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 209ms/step - d_loss: 0.6142 - g_loss: 0.8499\n",
      "Loss discriminator: 0.6113491058349609, Loss generator: 0.8678407669067383\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 208ms/step - d_loss: 0.6141 - g_loss: 0.8504\n",
      "Loss discriminator: 0.6106778383255005, Loss generator: 0.8686442375183105\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 207ms/step - d_loss: 0.6140 - g_loss: 0.8509\n",
      "Loss discriminator: 0.611290454864502, Loss generator: 0.8677777647972107\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 207ms/step - d_loss: 0.6140 - g_loss: 0.8513\n",
      "Loss discriminator: 0.6107576489448547, Loss generator: 0.8681586980819702\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m52s\u001b[0m 206ms/step - d_loss: 0.6138 - g_loss: 0.8518\n",
      "Loss discriminator: 0.6053083539009094, Loss generator: 0.877062976360321\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m47s\u001b[0m 205ms/step - d_loss: 0.6136 - g_loss: 0.8524\n",
      "Loss discriminator: 0.6059608459472656, Loss generator: 0.876805305480957\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m43s\u001b[0m 204ms/step - d_loss: 0.6135 - g_loss: 0.8529\n",
      "Loss discriminator: 0.6059406995773315, Loss generator: 0.8766388893127441\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - d_loss: 0.6133 - g_loss: 0.8535\n",
      "Loss discriminator: 0.6052449941635132, Loss generator: 0.8777347207069397\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m35s\u001b[0m 203ms/step - d_loss: 0.6131 - g_loss: 0.8540\n",
      "Loss discriminator: 0.6066991686820984, Loss generator: 0.8759556412696838\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m31s\u001b[0m 202ms/step - d_loss: 0.6130 - g_loss: 0.8544\n",
      "Loss discriminator: 0.6079705357551575, Loss generator: 0.8738604784011841\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 202ms/step - d_loss: 0.6129 - g_loss: 0.8548\n",
      "Loss discriminator: 0.607323944568634, Loss generator: 0.874796450138092\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 201ms/step - d_loss: 0.6128 - g_loss: 0.8552\n",
      "Loss discriminator: 0.6074433922767639, Loss generator: 0.8745354413986206\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 200ms/step - d_loss: 0.6127 - g_loss: 0.8556\n",
      "Loss discriminator: 0.6064420342445374, Loss generator: 0.8756456971168518\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 200ms/step - d_loss: 0.6125 - g_loss: 0.8560\n",
      "Loss discriminator: 0.6050190925598145, Loss generator: 0.8776782155036926\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - d_loss: 0.6124 - g_loss: 0.8564\n",
      "Loss discriminator: 0.6049985289573669, Loss generator: 0.8770517110824585\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - d_loss: 0.6123 - g_loss: 0.8568\n",
      "Loss discriminator: 0.6051377654075623, Loss generator: 0.8763458132743835\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - d_loss: 0.6121 - g_loss: 0.8572\n",
      "Loss discriminator: 0.6039558053016663, Loss generator: 0.8774456977844238\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 198ms/step - d_loss: 0.6120 - g_loss: 0.8575 - discriminator_loss: 0.6042 - generator_loss: 0.8772\n",
      "Epoch 4/20\n",
      "\n",
      "Loss discriminator: 0.6815013885498047, Loss generator: 0.7683136463165283\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 172ms/step - d_loss: 0.6792 - g_loss: 0.7883\n",
      "Loss discriminator: 0.6569342613220215, Loss generator: 0.8160223960876465\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 172ms/step - d_loss: 0.6537 - g_loss: 0.8233\n",
      "Loss discriminator: 0.5986620187759399, Loss generator: 0.8974373936653137\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 172ms/step - d_loss: 0.6300 - g_loss: 0.8554\n",
      "Loss discriminator: 0.5755299925804138, Loss generator: 0.9277841448783875\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 172ms/step - d_loss: 0.6175 - g_loss: 0.8711\n",
      "Loss discriminator: 0.5878936648368835, Loss generator: 0.9050156474113464\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 172ms/step - d_loss: 0.6104 - g_loss: 0.8795\n",
      "Loss discriminator: 0.5675655007362366, Loss generator: 0.9353304505348206\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 172ms/step - d_loss: 0.6018 - g_loss: 0.8912\n",
      "Loss discriminator: 0.5562357902526855, Loss generator: 0.9530293345451355\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:44\u001b[0m 172ms/step - d_loss: 0.5963 - g_loss: 0.8989\n",
      "Loss discriminator: 0.5707839727401733, Loss generator: 0.9355862736701965\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 172ms/step - d_loss: 0.5933 - g_loss: 0.9033\n",
      "Loss discriminator: 0.5709231495857239, Loss generator: 0.9373682737350464\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 172ms/step - d_loss: 0.5904 - g_loss: 0.9076\n",
      "Loss discriminator: 0.5650643110275269, Loss generator: 0.9448950886726379\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 173ms/step - d_loss: 0.5881 - g_loss: 0.9110\n",
      "Loss discriminator: 0.5715516209602356, Loss generator: 0.9358336329460144\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 173ms/step - d_loss: 0.5870 - g_loss: 0.9127\n",
      "Loss discriminator: 0.5772070288658142, Loss generator: 0.9263524413108826\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 172ms/step - d_loss: 0.5859 - g_loss: 0.9141\n",
      "Loss discriminator: 0.5712832808494568, Loss generator: 0.9335458874702454\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 172ms/step - d_loss: 0.5849 - g_loss: 0.9155\n",
      "Loss discriminator: 0.5735061168670654, Loss generator: 0.9301495552062988\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 173ms/step - d_loss: 0.5841 - g_loss: 0.9165\n",
      "Loss discriminator: 0.5743532776832581, Loss generator: 0.9296330809593201\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 172ms/step - d_loss: 0.5833 - g_loss: 0.9178\n",
      "Loss discriminator: 0.5679571628570557, Loss generator: 0.9422231316566467\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 173ms/step - d_loss: 0.5822 - g_loss: 0.9196\n",
      "Loss discriminator: 0.5631327629089355, Loss generator: 0.9504146575927734\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 173ms/step - d_loss: 0.5811 - g_loss: 0.9214\n",
      "Loss discriminator: 0.5641665458679199, Loss generator: 0.9481081366539001\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 173ms/step - d_loss: 0.5800 - g_loss: 0.9231\n",
      "Loss discriminator: 0.5564627051353455, Loss generator: 0.9608861207962036\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 173ms/step - d_loss: 0.5788 - g_loss: 0.9252\n",
      "Loss discriminator: 0.5621505379676819, Loss generator: 0.959323525428772\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 173ms/step - d_loss: 0.5783 - g_loss: 0.9265\n",
      "Loss discriminator: 0.5751882195472717, Loss generator: 0.9463033080101013\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 173ms/step - d_loss: 0.5781 - g_loss: 0.9275\n",
      "Loss discriminator: 0.5724945068359375, Loss generator: 0.9513281583786011\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 173ms/step - d_loss: 0.5777 - g_loss: 0.9288\n",
      "Loss discriminator: 0.567619800567627, Loss generator: 0.9601099491119385\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 173ms/step - d_loss: 0.5773 - g_loss: 0.9302\n",
      "Loss discriminator: 0.5674476623535156, Loss generator: 0.960210382938385\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 173ms/step - d_loss: 0.5768 - g_loss: 0.9314\n",
      "Loss discriminator: 0.5645096302032471, Loss generator: 0.9625396132469177\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 173ms/step - d_loss: 0.5763 - g_loss: 0.9328\n",
      "Loss discriminator: 0.5626194477081299, Loss generator: 0.9663221836090088\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 173ms/step - d_loss: 0.5758 - g_loss: 0.9340\n",
      "Loss discriminator: 0.5661327242851257, Loss generator: 0.96140056848526\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 173ms/step - d_loss: 0.5755 - g_loss: 0.9350\n",
      "Loss discriminator: 0.5669915676116943, Loss generator: 0.9599763751029968\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 173ms/step - d_loss: 0.5752 - g_loss: 0.9359\n",
      "Loss discriminator: 0.5655843615531921, Loss generator: 0.9613437652587891\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 173ms/step - d_loss: 0.5748 - g_loss: 0.9368\n",
      "Loss discriminator: 0.5647165775299072, Loss generator: 0.9621493816375732\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 173ms/step - d_loss: 0.5745 - g_loss: 0.9376\n",
      "Loss discriminator: 0.5640993118286133, Loss generator: 0.9612776041030884\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 173ms/step - d_loss: 0.5741 - g_loss: 0.9384\n",
      "Loss discriminator: 0.5612754225730896, Loss generator: 0.9642267227172852\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 173ms/step - d_loss: 0.5737 - g_loss: 0.9392\n",
      "Loss discriminator: 0.5604742765426636, Loss generator: 0.9657548069953918\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 173ms/step - d_loss: 0.5733 - g_loss: 0.9400\n",
      "Loss discriminator: 0.5617740154266357, Loss generator: 0.9644482731819153\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 173ms/step - d_loss: 0.5730 - g_loss: 0.9407\n",
      "Loss discriminator: 0.5611583590507507, Loss generator: 0.9656891226768494\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 173ms/step - d_loss: 0.5726 - g_loss: 0.9415\n",
      "Loss discriminator: 0.5613759160041809, Loss generator: 0.9654727578163147\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 173ms/step - d_loss: 0.5724 - g_loss: 0.9421\n",
      "Loss discriminator: 0.5654821991920471, Loss generator: 0.9594762921333313\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 173ms/step - d_loss: 0.5722 - g_loss: 0.9425\n",
      "Loss discriminator: 0.5655044913291931, Loss generator: 0.9587017893791199\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 173ms/step - d_loss: 0.5719 - g_loss: 0.9431\n",
      "Loss discriminator: 0.5582016706466675, Loss generator: 0.9739018082618713\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 173ms/step - d_loss: 0.5715 - g_loss: 0.9442\n",
      "Loss discriminator: 0.548244297504425, Loss generator: 0.9996357560157776\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 173ms/step - d_loss: 0.5707 - g_loss: 0.9459\n",
      "Loss discriminator: 0.5378332734107971, Loss generator: 1.0304805040359497\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 174ms/step - d_loss: 0.5699 - g_loss: 0.9480\n",
      "Loss discriminator: 0.5407888293266296, Loss generator: 1.0306490659713745\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m44s\u001b[0m 174ms/step - d_loss: 0.5693 - g_loss: 0.9500\n",
      "Loss discriminator: 0.5440019369125366, Loss generator: 1.0273929834365845\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m40s\u001b[0m 175ms/step - d_loss: 0.5687 - g_loss: 0.9518\n",
      "Loss discriminator: 0.5430676937103271, Loss generator: 1.0297551155090332\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 175ms/step - d_loss: 0.5681 - g_loss: 0.9535\n",
      "Loss discriminator: 0.5449123978614807, Loss generator: 1.0267566442489624\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m34s\u001b[0m 176ms/step - d_loss: 0.5677 - g_loss: 0.9551\n",
      "Loss discriminator: 0.5479992628097534, Loss generator: 1.0215774774551392\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 177ms/step - d_loss: 0.5672 - g_loss: 0.9565\n",
      "Loss discriminator: 0.5477055907249451, Loss generator: 1.0205817222595215\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 179ms/step - d_loss: 0.5668 - g_loss: 0.9579\n",
      "Loss discriminator: 0.5481616854667664, Loss generator: 1.0191974639892578\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - d_loss: 0.5664 - g_loss: 0.9592\n",
      "Loss discriminator: 0.548603355884552, Loss generator: 1.0179760456085205\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m20s\u001b[0m 182ms/step - d_loss: 0.5661 - g_loss: 0.9604\n",
      "Loss discriminator: 0.547690212726593, Loss generator: 1.0191564559936523\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 183ms/step - d_loss: 0.5657 - g_loss: 0.9615\n",
      "Loss discriminator: 0.5470399260520935, Loss generator: 1.019449234008789\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 184ms/step - d_loss: 0.5653 - g_loss: 0.9627\n",
      "Loss discriminator: 0.5478432178497314, Loss generator: 1.0172873735427856\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 185ms/step - d_loss: 0.5650 - g_loss: 0.9637\n",
      "Loss discriminator: 0.5463372468948364, Loss generator: 1.0185887813568115\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 187ms/step - d_loss: 0.5646 - g_loss: 0.9648\n",
      "Loss discriminator: 0.5446500778198242, Loss generator: 1.0208320617675781\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 188ms/step - d_loss: 0.5642 - g_loss: 0.9658\n",
      "Loss discriminator: 0.5449920892715454, Loss generator: 1.0198975801467896\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 188ms/step - d_loss: 0.5640 - g_loss: 0.9665 - discriminator_loss: 0.5448 - generator_loss: 1.0204\n",
      "Epoch 5/20\n",
      "\n",
      "Loss discriminator: 0.5005267262458801, Loss generator: 1.163259744644165\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 250ms/step - d_loss: 0.4728 - g_loss: 1.1488\n",
      "Loss discriminator: 0.4473535418510437, Loss generator: 1.1758067607879639\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:23\u001b[0m 250ms/step - d_loss: 0.4567 - g_loss: 1.1761\n",
      "Loss discriminator: 0.43990907073020935, Loss generator: 1.2142452001571655\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 249ms/step - d_loss: 0.4568 - g_loss: 1.1765\n",
      "Loss discriminator: 0.4826391339302063, Loss generator: 1.1306889057159424\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 249ms/step - d_loss: 0.4691 - g_loss: 1.1540\n",
      "Loss discriminator: 0.5227144956588745, Loss generator: 1.0537856817245483\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 249ms/step - d_loss: 0.4789 - g_loss: 1.1344\n",
      "Loss discriminator: 0.5121080279350281, Loss generator: 1.0642157793045044\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 249ms/step - d_loss: 0.4850 - g_loss: 1.1221\n",
      "Loss discriminator: 0.5215399265289307, Loss generator: 1.050064206123352\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 249ms/step - d_loss: 0.4911 - g_loss: 1.1105\n",
      "Loss discriminator: 0.5328280925750732, Loss generator: 1.0335693359375\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 249ms/step - d_loss: 0.4962 - g_loss: 1.1009\n",
      "Loss discriminator: 0.5272963047027588, Loss generator: 1.0384279489517212\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:47\u001b[0m 249ms/step - d_loss: 0.4990 - g_loss: 1.0950\n",
      "Loss discriminator: 0.5174356698989868, Loss generator: 1.0542043447494507\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 249ms/step - d_loss: 0.5008 - g_loss: 1.0909\n",
      "Loss discriminator: 0.5169439911842346, Loss generator: 1.0513558387756348\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:37\u001b[0m 249ms/step - d_loss: 0.5024 - g_loss: 1.0868\n",
      "Loss discriminator: 0.5199912786483765, Loss generator: 1.0404846668243408\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 250ms/step - d_loss: 0.5037 - g_loss: 1.0831\n",
      "Loss discriminator: 0.514349102973938, Loss generator: 1.0478858947753906\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 250ms/step - d_loss: 0.5043 - g_loss: 1.0807\n",
      "Loss discriminator: 0.5104567408561707, Loss generator: 1.0537748336791992\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 250ms/step - d_loss: 0.5049 - g_loss: 1.0786\n",
      "Loss discriminator: 0.5142101645469666, Loss generator: 1.0470201969146729\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 250ms/step - d_loss: 0.5055 - g_loss: 1.0764\n",
      "Loss discriminator: 0.5145536661148071, Loss generator: 1.0462702512741089\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 250ms/step - d_loss: 0.5060 - g_loss: 1.0747\n",
      "Loss discriminator: 0.5111093521118164, Loss generator: 1.0519912242889404\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 249ms/step - d_loss: 0.5063 - g_loss: 1.0733\n",
      "Loss discriminator: 0.5135584473609924, Loss generator: 1.0489740371704102\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 249ms/step - d_loss: 0.5070 - g_loss: 1.0716\n",
      "Loss discriminator: 0.5215120315551758, Loss generator: 1.0363903045654297\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 247ms/step - d_loss: 0.5076 - g_loss: 1.0700\n",
      "Loss discriminator: 0.5132084488868713, Loss generator: 1.0514127016067505\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 247ms/step - d_loss: 0.5078 - g_loss: 1.0693\n",
      "Loss discriminator: 0.5120536088943481, Loss generator: 1.0561774969100952\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 247ms/step - d_loss: 0.5081 - g_loss: 1.0686\n",
      "Loss discriminator: 0.5161653757095337, Loss generator: 1.053274154663086\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 247ms/step - d_loss: 0.5084 - g_loss: 1.0680\n",
      "Loss discriminator: 0.5139715075492859, Loss generator: 1.0578150749206543\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 248ms/step - d_loss: 0.5086 - g_loss: 1.0676\n",
      "Loss discriminator: 0.5106775164604187, Loss generator: 1.064121961593628\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 248ms/step - d_loss: 0.5087 - g_loss: 1.0675\n",
      "Loss discriminator: 0.5112507343292236, Loss generator: 1.0626739263534546\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 248ms/step - d_loss: 0.5089 - g_loss: 1.0671\n",
      "Loss discriminator: 0.5163042545318604, Loss generator: 1.0541167259216309\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 248ms/step - d_loss: 0.5091 - g_loss: 1.0669\n",
      "Loss discriminator: 0.5075818300247192, Loss generator: 1.0739951133728027\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 248ms/step - d_loss: 0.5088 - g_loss: 1.0676\n",
      "Loss discriminator: 0.5016841888427734, Loss generator: 1.091263771057129\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 247ms/step - d_loss: 0.5087 - g_loss: 1.0683\n",
      "Loss discriminator: 0.5071806907653809, Loss generator: 1.0859140157699585\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 247ms/step - d_loss: 0.5086 - g_loss: 1.0689\n",
      "Loss discriminator: 0.5067318081855774, Loss generator: 1.0871189832687378\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 247ms/step - d_loss: 0.5085 - g_loss: 1.0696\n",
      "Loss discriminator: 0.5041625499725342, Loss generator: 1.092688798904419\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 247ms/step - d_loss: 0.5084 - g_loss: 1.0703\n",
      "Loss discriminator: 0.5046814680099487, Loss generator: 1.092223882675171\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 247ms/step - d_loss: 0.5083 - g_loss: 1.0709\n",
      "Loss discriminator: 0.5076050758361816, Loss generator: 1.087069034576416\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 247ms/step - d_loss: 0.5083 - g_loss: 1.0714\n",
      "Loss discriminator: 0.5062741637229919, Loss generator: 1.0876177549362183\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 247ms/step - d_loss: 0.5082 - g_loss: 1.0720\n",
      "Loss discriminator: 0.5031184554100037, Loss generator: 1.0928184986114502\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 246ms/step - d_loss: 0.5080 - g_loss: 1.0726\n",
      "Loss discriminator: 0.5035310983657837, Loss generator: 1.0914220809936523\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 246ms/step - d_loss: 0.5079 - g_loss: 1.0731\n",
      "Loss discriminator: 0.5033119320869446, Loss generator: 1.0919277667999268\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 246ms/step - d_loss: 0.5078 - g_loss: 1.0736\n",
      "Loss discriminator: 0.5017254948616028, Loss generator: 1.0942273139953613\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 246ms/step - d_loss: 0.5076 - g_loss: 1.0742\n",
      "Loss discriminator: 0.5014738440513611, Loss generator: 1.0937687158584595\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 246ms/step - d_loss: 0.5075 - g_loss: 1.0746\n",
      "Loss discriminator: 0.5030431747436523, Loss generator: 1.0906468629837036\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 246ms/step - d_loss: 0.5074 - g_loss: 1.0750\n",
      "Loss discriminator: 0.5040960311889648, Loss generator: 1.0877840518951416\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 246ms/step - d_loss: 0.5073 - g_loss: 1.0754\n",
      "Loss discriminator: 0.5006051063537598, Loss generator: 1.0937563180923462\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 246ms/step - d_loss: 0.5071 - g_loss: 1.0759\n",
      "Loss discriminator: 0.49884310364723206, Loss generator: 1.0966742038726807\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m57s\u001b[0m 246ms/step - d_loss: 0.5069 - g_loss: 1.0763\n",
      "Loss discriminator: 0.4991101622581482, Loss generator: 1.0962644815444946\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m52s\u001b[0m 246ms/step - d_loss: 0.5067 - g_loss: 1.0768\n",
      "Loss discriminator: 0.4984443783760071, Loss generator: 1.0969891548156738\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m47s\u001b[0m 246ms/step - d_loss: 0.5065 - g_loss: 1.0773\n",
      "Loss discriminator: 0.4963814616203308, Loss generator: 1.100927472114563\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m42s\u001b[0m 245ms/step - d_loss: 0.5063 - g_loss: 1.0778\n",
      "Loss discriminator: 0.49636951088905334, Loss generator: 1.1008061170578003\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m37s\u001b[0m 245ms/step - d_loss: 0.5061 - g_loss: 1.0783\n",
      "Loss discriminator: 0.49765095114707947, Loss generator: 1.09769868850708\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m32s\u001b[0m 245ms/step - d_loss: 0.5059 - g_loss: 1.0787\n",
      "Loss discriminator: 0.494721919298172, Loss generator: 1.102683663368225\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m27s\u001b[0m 245ms/step - d_loss: 0.5056 - g_loss: 1.0793\n",
      "Loss discriminator: 0.49151381850242615, Loss generator: 1.1094214916229248\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - d_loss: 0.5053 - g_loss: 1.0799\n",
      "Loss discriminator: 0.4916602671146393, Loss generator: 1.1093676090240479\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 245ms/step - d_loss: 0.5051 - g_loss: 1.0805\n",
      "Loss discriminator: 0.49140989780426025, Loss generator: 1.109963297843933\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 245ms/step - d_loss: 0.5048 - g_loss: 1.0810\n",
      "Loss discriminator: 0.4915047883987427, Loss generator: 1.1100026369094849\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - d_loss: 0.5046 - g_loss: 1.0815\n",
      "Loss discriminator: 0.4931306838989258, Loss generator: 1.106798529624939\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - d_loss: 0.5044 - g_loss: 1.0820\n",
      "Loss discriminator: 0.4929766058921814, Loss generator: 1.10592520236969\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 245ms/step - d_loss: 0.5042 - g_loss: 1.0823 - discriminator_loss: 0.4914 - generator_loss: 1.1080\n",
      "Epoch 6/20\n",
      "\n",
      "Loss discriminator: 0.36725953221321106, Loss generator: 1.3626056909561157\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:23\u001b[0m 246ms/step - d_loss: 0.3829 - g_loss: 1.3122\n",
      "Loss discriminator: 0.4019838571548462, Loss generator: 1.2700413465499878\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 248ms/step - d_loss: 0.4004 - g_loss: 1.2775\n",
      "Loss discriminator: 0.43253129720687866, Loss generator: 1.2231794595718384\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:16\u001b[0m 248ms/step - d_loss: 0.4114 - g_loss: 1.2583\n",
      "Loss discriminator: 0.43166089057922363, Loss generator: 1.224382996559143\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10\u001b[0m 247ms/step - d_loss: 0.4161 - g_loss: 1.2509\n",
      "Loss discriminator: 0.43101736903190613, Loss generator: 1.226269006729126\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05\u001b[0m 247ms/step - d_loss: 0.4208 - g_loss: 1.2423\n",
      "Loss discriminator: 0.4493037760257721, Loss generator: 1.1882357597351074\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:59\u001b[0m 246ms/step - d_loss: 0.4265 - g_loss: 1.2315\n",
      "Loss discriminator: 0.4559050500392914, Loss generator: 1.1707051992416382\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:53\u001b[0m 245ms/step - d_loss: 0.4291 - g_loss: 1.2260\n",
      "Loss discriminator: 0.43017396330833435, Loss generator: 1.2281017303466797\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:47\u001b[0m 244ms/step - d_loss: 0.4282 - g_loss: 1.2288\n",
      "Loss discriminator: 0.41799286007881165, Loss generator: 1.2612041234970093\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:43\u001b[0m 245ms/step - d_loss: 0.4276 - g_loss: 1.2319\n",
      "Loss discriminator: 0.4272438585758209, Loss generator: 1.2513898611068726\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:38\u001b[0m 244ms/step - d_loss: 0.4276 - g_loss: 1.2339\n",
      "Loss discriminator: 0.4270435869693756, Loss generator: 1.2572333812713623\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 244ms/step - d_loss: 0.4274 - g_loss: 1.2366\n",
      "Loss discriminator: 0.423608660697937, Loss generator: 1.2669974565505981\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 244ms/step - d_loss: 0.4273 - g_loss: 1.2386\n",
      "Loss discriminator: 0.43153268098831177, Loss generator: 1.2502175569534302\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 244ms/step - d_loss: 0.4282 - g_loss: 1.2385\n",
      "Loss discriminator: 0.44410109519958496, Loss generator: 1.2275387048721313\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:18\u001b[0m 244ms/step - d_loss: 0.4292 - g_loss: 1.2379\n",
      "Loss discriminator: 0.43786248564720154, Loss generator: 1.241832971572876\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:14\u001b[0m 244ms/step - d_loss: 0.4292 - g_loss: 1.2399\n",
      "Loss discriminator: 0.4198317229747772, Loss generator: 1.3011959791183472\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 244ms/step - d_loss: 0.4280 - g_loss: 1.2461\n",
      "Loss discriminator: 0.39936885237693787, Loss generator: 1.3843013048171997\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 244ms/step - d_loss: 0.4258 - g_loss: 1.2569\n",
      "Loss discriminator: 0.3799270689487457, Loss generator: 1.4769752025604248\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 244ms/step - d_loss: 0.4232 - g_loss: 1.2697\n",
      "Loss discriminator: 0.38686424493789673, Loss generator: 1.4789575338363647\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 243ms/step - d_loss: 0.4217 - g_loss: 1.2800\n",
      "Loss discriminator: 0.4018811285495758, Loss generator: 1.453866720199585\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 242ms/step - d_loss: 0.4208 - g_loss: 1.2885\n",
      "Loss discriminator: 0.4026618003845215, Loss generator: 1.4454665184020996\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 242ms/step - d_loss: 0.4199 - g_loss: 1.2959\n",
      "Loss discriminator: 0.40241503715515137, Loss generator: 1.4415379762649536\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 242ms/step - d_loss: 0.4192 - g_loss: 1.3022\n",
      "Loss discriminator: 0.4092165231704712, Loss generator: 1.424059510231018\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 242ms/step - d_loss: 0.4189 - g_loss: 1.3071\n",
      "Loss discriminator: 0.41315874457359314, Loss generator: 1.4098751544952393\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 242ms/step - d_loss: 0.4186 - g_loss: 1.3115\n",
      "Loss discriminator: 0.4100342094898224, Loss generator: 1.4121503829956055\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 243ms/step - d_loss: 0.4183 - g_loss: 1.3153\n",
      "Loss discriminator: 0.41158953309059143, Loss generator: 1.403214693069458\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:19\u001b[0m 243ms/step - d_loss: 0.4181 - g_loss: 1.3186\n",
      "Loss discriminator: 0.41213077306747437, Loss generator: 1.3973088264465332\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 243ms/step - d_loss: 0.4178 - g_loss: 1.3215\n",
      "Loss discriminator: 0.41065627336502075, Loss generator: 1.3958944082260132\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 243ms/step - d_loss: 0.4175 - g_loss: 1.3241\n",
      "Loss discriminator: 0.40918198227882385, Loss generator: 1.3940716981887817\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 244ms/step - d_loss: 0.4173 - g_loss: 1.3264\n",
      "Loss discriminator: 0.4103345274925232, Loss generator: 1.3862149715423584\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 242ms/step - d_loss: 0.4171 - g_loss: 1.3283\n",
      "Loss discriminator: 0.41192230582237244, Loss generator: 1.3780189752578735\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 241ms/step - d_loss: 0.4169 - g_loss: 1.3298\n",
      "Loss discriminator: 0.41172918677330017, Loss generator: 1.3737071752548218\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 239ms/step - d_loss: 0.4167 - g_loss: 1.3312\n",
      "Loss discriminator: 0.40984973311424255, Loss generator: 1.3733069896697998\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 237ms/step - d_loss: 0.4165 - g_loss: 1.3324\n",
      "Loss discriminator: 0.4088479280471802, Loss generator: 1.3710417747497559\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 235ms/step - d_loss: 0.4163 - g_loss: 1.3335\n",
      "Loss discriminator: 0.40897685289382935, Loss generator: 1.3689266443252563\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 233ms/step - d_loss: 0.4160 - g_loss: 1.3345\n",
      "Loss discriminator: 0.4081512689590454, Loss generator: 1.3683313131332397\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 232ms/step - d_loss: 0.4158 - g_loss: 1.3355\n",
      "Loss discriminator: 0.4063345193862915, Loss generator: 1.3707237243652344\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 230ms/step - d_loss: 0.4155 - g_loss: 1.3365\n",
      "Loss discriminator: 0.4053046405315399, Loss generator: 1.3700591325759888\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 229ms/step - d_loss: 0.4153 - g_loss: 1.3373\n",
      "Loss discriminator: 0.4069470167160034, Loss generator: 1.3641655445098877\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 227ms/step - d_loss: 0.4151 - g_loss: 1.3379\n",
      "Loss discriminator: 0.40657466650009155, Loss generator: 1.361566185951233\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 226ms/step - d_loss: 0.4148 - g_loss: 1.3386\n",
      "Loss discriminator: 0.40375322103500366, Loss generator: 1.3666465282440186\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 225ms/step - d_loss: 0.4145 - g_loss: 1.3392\n",
      "Loss discriminator: 0.4037407338619232, Loss generator: 1.36587655544281\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m56s\u001b[0m 224ms/step - d_loss: 0.4143 - g_loss: 1.3398\n",
      "Loss discriminator: 0.40506795048713684, Loss generator: 1.3632177114486694\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m52s\u001b[0m 222ms/step - d_loss: 0.4141 - g_loss: 1.3404\n",
      "Loss discriminator: 0.4030265212059021, Loss generator: 1.3671411275863647\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m47s\u001b[0m 221ms/step - d_loss: 0.4138 - g_loss: 1.3411\n",
      "Loss discriminator: 0.40115082263946533, Loss generator: 1.3716679811477661\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m42s\u001b[0m 220ms/step - d_loss: 0.4135 - g_loss: 1.3418\n",
      "Loss discriminator: 0.4024239778518677, Loss generator: 1.368588924407959\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38s\u001b[0m 219ms/step - d_loss: 0.4133 - g_loss: 1.3423\n",
      "Loss discriminator: 0.4033288359642029, Loss generator: 1.3648335933685303\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m33s\u001b[0m 218ms/step - d_loss: 0.4130 - g_loss: 1.3429\n",
      "Loss discriminator: 0.39915794134140015, Loss generator: 1.3779592514038086\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m29s\u001b[0m 217ms/step - d_loss: 0.4127 - g_loss: 1.3437\n",
      "Loss discriminator: 0.3980308175086975, Loss generator: 1.3832331895828247\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - d_loss: 0.4125 - g_loss: 1.3445\n",
      "Loss discriminator: 0.3995685279369354, Loss generator: 1.3800338506698608\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m20s\u001b[0m 216ms/step - d_loss: 0.4122 - g_loss: 1.3452\n",
      "Loss discriminator: 0.3994195759296417, Loss generator: 1.380233645439148\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 215ms/step - d_loss: 0.4119 - g_loss: 1.3459\n",
      "Loss discriminator: 0.39839842915534973, Loss generator: 1.3810495138168335\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m11s\u001b[0m 214ms/step - d_loss: 0.4117 - g_loss: 1.3465\n",
      "Loss discriminator: 0.3986200988292694, Loss generator: 1.3794647455215454\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 213ms/step - d_loss: 0.4114 - g_loss: 1.3471\n",
      "Loss discriminator: 0.40007326006889343, Loss generator: 1.3750718832015991\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - d_loss: 0.4112 - g_loss: 1.3476\n",
      "Loss discriminator: 0.39829596877098083, Loss generator: 1.377446174621582\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 212ms/step - d_loss: 0.4110 - g_loss: 1.3481 - discriminator_loss: 0.3965 - generator_loss: 1.3824\n",
      "Epoch 7/20\n",
      "\n",
      "Loss discriminator: 0.27627700567245483, Loss generator: 1.8663129806518555\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:13\u001b[0m 180ms/step - d_loss: 0.3357 - g_loss: 1.5730\n",
      "Loss discriminator: 0.3695017695426941, Loss generator: 1.4694684743881226\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:08\u001b[0m 179ms/step - d_loss: 0.3577 - g_loss: 1.5015\n",
      "Loss discriminator: 0.379171222448349, Loss generator: 1.421073317527771\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 178ms/step - d_loss: 0.3621 - g_loss: 1.4784\n",
      "Loss discriminator: 0.3631555736064911, Loss generator: 1.445927619934082\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 177ms/step - d_loss: 0.3625 - g_loss: 1.4706\n",
      "Loss discriminator: 0.36705291271209717, Loss generator: 1.4361653327941895\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 177ms/step - d_loss: 0.3651 - g_loss: 1.4589\n",
      "Loss discriminator: 0.38082486391067505, Loss generator: 1.3960570096969604\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 178ms/step - d_loss: 0.3676 - g_loss: 1.4476\n",
      "Loss discriminator: 0.3763265907764435, Loss generator: 1.392524003982544\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 178ms/step - d_loss: 0.3678 - g_loss: 1.4418\n",
      "Loss discriminator: 0.3619679808616638, Loss generator: 1.4209060668945312\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 178ms/step - d_loss: 0.3667 - g_loss: 1.4400\n",
      "Loss discriminator: 0.3586115837097168, Loss generator: 1.4292817115783691\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 179ms/step - d_loss: 0.3661 - g_loss: 1.4381\n",
      "Loss discriminator: 0.3634406328201294, Loss generator: 1.4163310527801514\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 179ms/step - d_loss: 0.3659 - g_loss: 1.4357\n",
      "Loss discriminator: 0.36386534571647644, Loss generator: 1.4170491695404053\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 181ms/step - d_loss: 0.3656 - g_loss: 1.4343\n",
      "Loss discriminator: 0.3607570230960846, Loss generator: 1.4244612455368042\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:35\u001b[0m 182ms/step - d_loss: 0.3651 - g_loss: 1.4337\n",
      "Loss discriminator: 0.3601778447628021, Loss generator: 1.4255881309509277\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 184ms/step - d_loss: 0.3648 - g_loss: 1.4328\n",
      "Loss discriminator: 0.3600374460220337, Loss generator: 1.4219987392425537\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 185ms/step - d_loss: 0.3643 - g_loss: 1.4324\n",
      "Loss discriminator: 0.35395827889442444, Loss generator: 1.4360750913619995\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 187ms/step - d_loss: 0.3633 - g_loss: 1.4337\n",
      "Loss discriminator: 0.3428429365158081, Loss generator: 1.4758961200714111\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 192ms/step - d_loss: 0.3617 - g_loss: 1.4374\n",
      "Loss discriminator: 0.3352351784706116, Loss generator: 1.5085376501083374\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 195ms/step - d_loss: 0.3603 - g_loss: 1.4416\n",
      "Loss discriminator: 0.3416846990585327, Loss generator: 1.50184965133667\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 199ms/step - d_loss: 0.3594 - g_loss: 1.4446\n",
      "Loss discriminator: 0.34704530239105225, Loss generator: 1.4920116662979126\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:23\u001b[0m 201ms/step - d_loss: 0.3588 - g_loss: 1.4470\n",
      "Loss discriminator: 0.3479100465774536, Loss generator: 1.4910557270050049\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 204ms/step - d_loss: 0.3583 - g_loss: 1.4490\n",
      "Loss discriminator: 0.3515533208847046, Loss generator: 1.4796472787857056\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 206ms/step - d_loss: 0.3580 - g_loss: 1.4503\n",
      "Loss discriminator: 0.3506758511066437, Loss generator: 1.480400800704956\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 208ms/step - d_loss: 0.3576 - g_loss: 1.4521\n",
      "Loss discriminator: 0.3448869287967682, Loss generator: 1.4977977275848389\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 210ms/step - d_loss: 0.3570 - g_loss: 1.4542\n",
      "Loss discriminator: 0.34477370977401733, Loss generator: 1.5021934509277344\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 212ms/step - d_loss: 0.3565 - g_loss: 1.4561\n",
      "Loss discriminator: 0.3472648859024048, Loss generator: 1.4969779253005981\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 214ms/step - d_loss: 0.3561 - g_loss: 1.4577\n",
      "Loss discriminator: 0.34703418612480164, Loss generator: 1.4966669082641602\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 215ms/step - d_loss: 0.3558 - g_loss: 1.4592\n",
      "Loss discriminator: 0.3456264138221741, Loss generator: 1.497962474822998\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 217ms/step - d_loss: 0.3554 - g_loss: 1.4607\n",
      "Loss discriminator: 0.3450518846511841, Loss generator: 1.4977257251739502\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 218ms/step - d_loss: 0.3550 - g_loss: 1.4619\n",
      "Loss discriminator: 0.3455314040184021, Loss generator: 1.494847059249878\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 219ms/step - d_loss: 0.3547 - g_loss: 1.4631\n",
      "Loss discriminator: 0.34319987893104553, Loss generator: 1.4993244409561157\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 220ms/step - d_loss: 0.3542 - g_loss: 1.4645\n",
      "Loss discriminator: 0.3405901789665222, Loss generator: 1.5099369287490845\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 221ms/step - d_loss: 0.3538 - g_loss: 1.4660\n",
      "Loss discriminator: 0.34228479862213135, Loss generator: 1.5084089040756226\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 222ms/step - d_loss: 0.3535 - g_loss: 1.4673\n",
      "Loss discriminator: 0.34208759665489197, Loss generator: 1.5106201171875\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 223ms/step - d_loss: 0.3531 - g_loss: 1.4687\n",
      "Loss discriminator: 0.3399321734905243, Loss generator: 1.5174872875213623\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 224ms/step - d_loss: 0.3527 - g_loss: 1.4702\n",
      "Loss discriminator: 0.3392573595046997, Loss generator: 1.5195600986480713\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 225ms/step - d_loss: 0.3523 - g_loss: 1.4716\n",
      "Loss discriminator: 0.3412040174007416, Loss generator: 1.5147535800933838\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 225ms/step - d_loss: 0.3520 - g_loss: 1.4728\n",
      "Loss discriminator: 0.34002944827079773, Loss generator: 1.5174827575683594\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 226ms/step - d_loss: 0.3516 - g_loss: 1.4742\n",
      "Loss discriminator: 0.3372839689254761, Loss generator: 1.5293033123016357\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 227ms/step - d_loss: 0.3513 - g_loss: 1.4756\n",
      "Loss discriminator: 0.3396407663822174, Loss generator: 1.5260324478149414\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 227ms/step - d_loss: 0.3510 - g_loss: 1.4769\n",
      "Loss discriminator: 0.33961546421051025, Loss generator: 1.5287272930145264\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 228ms/step - d_loss: 0.3507 - g_loss: 1.4783\n",
      "Loss discriminator: 0.3367812931537628, Loss generator: 1.5401341915130615\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 227ms/step - d_loss: 0.3503 - g_loss: 1.4799\n",
      "Loss discriminator: 0.3354640603065491, Loss generator: 1.544686198234558\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m57s\u001b[0m 226ms/step - d_loss: 0.3500 - g_loss: 1.4814\n",
      "Loss discriminator: 0.3363177180290222, Loss generator: 1.5412511825561523\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m52s\u001b[0m 225ms/step - d_loss: 0.3497 - g_loss: 1.4827\n",
      "Loss discriminator: 0.33818212151527405, Loss generator: 1.5345985889434814\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m48s\u001b[0m 226ms/step - d_loss: 0.3494 - g_loss: 1.4839\n",
      "Loss discriminator: 0.33647578954696655, Loss generator: 1.5396231412887573\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m44s\u001b[0m 227ms/step - d_loss: 0.3491 - g_loss: 1.4852\n",
      "Loss discriminator: 0.33616819977760315, Loss generator: 1.5417543649673462\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m39s\u001b[0m 228ms/step - d_loss: 0.3488 - g_loss: 1.4864\n",
      "Loss discriminator: 0.3368734121322632, Loss generator: 1.5396989583969116\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 228ms/step - d_loss: 0.3486 - g_loss: 1.4876\n",
      "Loss discriminator: 0.3356274962425232, Loss generator: 1.5429571866989136\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m30s\u001b[0m 228ms/step - d_loss: 0.3483 - g_loss: 1.4888\n",
      "Loss discriminator: 0.33418965339660645, Loss generator: 1.5466701984405518\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 229ms/step - d_loss: 0.3480 - g_loss: 1.4900\n",
      "Loss discriminator: 0.33420470356941223, Loss generator: 1.5464755296707153\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m21s\u001b[0m 229ms/step - d_loss: 0.3477 - g_loss: 1.4911\n",
      "Loss discriminator: 0.335098534822464, Loss generator: 1.5429072380065918\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 230ms/step - d_loss: 0.3475 - g_loss: 1.4921\n",
      "Loss discriminator: 0.33293208479881287, Loss generator: 1.5502004623413086\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - d_loss: 0.3472 - g_loss: 1.4934\n",
      "Loss discriminator: 0.3307378888130188, Loss generator: 1.5659602880477905\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - d_loss: 0.3469 - g_loss: 1.4948\n",
      "Loss discriminator: 0.3325885236263275, Loss generator: 1.5645208358764648\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 231ms/step - d_loss: 0.3466 - g_loss: 1.4960\n",
      "Loss discriminator: 0.33234328031539917, Loss generator: 1.5647767782211304\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 231ms/step - d_loss: 0.3464 - g_loss: 1.4969 - discriminator_loss: 0.3310 - generator_loss: 1.5691\n",
      "Epoch 8/20\n",
      "\n",
      "Loss discriminator: 0.2132648229598999, Loss generator: 2.115861177444458\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:28\u001b[0m 250ms/step - d_loss: 0.2160 - g_loss: 2.0339\n",
      "Loss discriminator: 0.22837041318416595, Loss generator: 1.9335691928863525\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 249ms/step - d_loss: 0.2332 - g_loss: 1.9417\n",
      "Loss discriminator: 0.2731826603412628, Loss generator: 1.760589599609375\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 249ms/step - d_loss: 0.2520 - g_loss: 1.8625\n",
      "Loss discriminator: 0.3019378185272217, Loss generator: 1.6470187902450562\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 249ms/step - d_loss: 0.2648 - g_loss: 1.8043\n",
      "Loss discriminator: 0.301421582698822, Loss generator: 1.62371826171875\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 249ms/step - d_loss: 0.2720 - g_loss: 1.7688\n",
      "Loss discriminator: 0.30332881212234497, Loss generator: 1.6181806325912476\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 249ms/step - d_loss: 0.2782 - g_loss: 1.7413\n",
      "Loss discriminator: 0.3139743506908417, Loss generator: 1.5928940773010254\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 249ms/step - d_loss: 0.2834 - g_loss: 1.7185\n",
      "Loss discriminator: 0.3152065575122833, Loss generator: 1.5765799283981323\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:53\u001b[0m 250ms/step - d_loss: 0.2877 - g_loss: 1.6998\n",
      "Loss discriminator: 0.32158535718917847, Loss generator: 1.5542733669281006\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:48\u001b[0m 250ms/step - d_loss: 0.2917 - g_loss: 1.6825\n",
      "Loss discriminator: 0.32495740056037903, Loss generator: 1.536318063735962\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:43\u001b[0m 250ms/step - d_loss: 0.2952 - g_loss: 1.6675\n",
      "Loss discriminator: 0.33044174313545227, Loss generator: 1.5258629322052002\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:38\u001b[0m 250ms/step - d_loss: 0.2987 - g_loss: 1.6540\n",
      "Loss discriminator: 0.3350438177585602, Loss generator: 1.5160086154937744\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:33\u001b[0m 250ms/step - d_loss: 0.3020 - g_loss: 1.6419\n",
      "Loss discriminator: 0.3461731970310211, Loss generator: 1.4954270124435425\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:28\u001b[0m 250ms/step - d_loss: 0.3055 - g_loss: 1.6315\n",
      "Loss discriminator: 0.34028735756874084, Loss generator: 1.5538885593414307\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 250ms/step - d_loss: 0.3072 - g_loss: 1.6319\n",
      "Loss discriminator: 0.3203558623790741, Loss generator: 1.7250694036483765\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 248ms/step - d_loss: 0.3083 - g_loss: 1.6403\n",
      "Loss discriminator: 0.3230159878730774, Loss generator: 1.7965337038040161\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 247ms/step - d_loss: 0.3089 - g_loss: 1.6527\n",
      "Loss discriminator: 0.31044065952301025, Loss generator: 1.8830150365829468\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 248ms/step - d_loss: 0.3087 - g_loss: 1.6681\n",
      "Loss discriminator: 0.29959383606910706, Loss generator: 1.9448206424713135\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 248ms/step - d_loss: 0.3079 - g_loss: 1.6847\n",
      "Loss discriminator: 0.2897323966026306, Loss generator: 1.9930602312088013\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 248ms/step - d_loss: 0.3067 - g_loss: 1.7017\n",
      "Loss discriminator: 0.2834204435348511, Loss generator: 2.014848232269287\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 248ms/step - d_loss: 0.3055 - g_loss: 1.7172\n",
      "Loss discriminator: 0.2831841707229614, Loss generator: 2.005187749862671\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 248ms/step - d_loss: 0.3046 - g_loss: 1.7304\n",
      "Loss discriminator: 0.2894544005393982, Loss generator: 1.9784880876541138\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 248ms/step - d_loss: 0.3041 - g_loss: 1.7409\n",
      "Loss discriminator: 0.3002883791923523, Loss generator: 1.9403938055038452\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 248ms/step - d_loss: 0.3042 - g_loss: 1.7488\n",
      "Loss discriminator: 0.3119848966598511, Loss generator: 1.9022012948989868\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 248ms/step - d_loss: 0.3048 - g_loss: 1.7543\n",
      "Loss discriminator: 0.3254665732383728, Loss generator: 1.8614100217819214\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 248ms/step - d_loss: 0.3059 - g_loss: 1.7578\n",
      "Loss discriminator: 0.3414720296859741, Loss generator: 1.8205195665359497\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 248ms/step - d_loss: 0.3076 - g_loss: 1.7595\n",
      "Loss discriminator: 0.3561168611049652, Loss generator: 1.7812232971191406\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 248ms/step - d_loss: 0.3096 - g_loss: 1.7597\n",
      "Loss discriminator: 0.3698127865791321, Loss generator: 1.744908094406128\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 248ms/step - d_loss: 0.3120 - g_loss: 1.7586\n",
      "Loss discriminator: 0.38226550817489624, Loss generator: 1.7111599445343018\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 249ms/step - d_loss: 0.3146 - g_loss: 1.7564\n",
      "Loss discriminator: 0.3939533233642578, Loss generator: 1.6796588897705078\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 249ms/step - d_loss: 0.3174 - g_loss: 1.7534\n",
      "Loss discriminator: 0.40414533019065857, Loss generator: 1.6504533290863037\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 249ms/step - d_loss: 0.3203 - g_loss: 1.7496\n",
      "Loss discriminator: 0.4138377606868744, Loss generator: 1.622348427772522\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 249ms/step - d_loss: 0.3234 - g_loss: 1.7453\n",
      "Loss discriminator: 0.42346540093421936, Loss generator: 1.5958876609802246\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 249ms/step - d_loss: 0.3266 - g_loss: 1.7404\n",
      "Loss discriminator: 0.4325925409793854, Loss generator: 1.5709292888641357\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 249ms/step - d_loss: 0.3298 - g_loss: 1.7351\n",
      "Loss discriminator: 0.4403221011161804, Loss generator: 1.5488048791885376\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 249ms/step - d_loss: 0.3331 - g_loss: 1.7295\n",
      "Loss discriminator: 0.44761785864830017, Loss generator: 1.5269767045974731\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 249ms/step - d_loss: 0.3363 - g_loss: 1.7235\n",
      "Loss discriminator: 0.4549545347690582, Loss generator: 1.5056607723236084\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 249ms/step - d_loss: 0.3396 - g_loss: 1.7174\n",
      "Loss discriminator: 0.4617612957954407, Loss generator: 1.4865649938583374\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 249ms/step - d_loss: 0.3429 - g_loss: 1.7111\n",
      "Loss discriminator: 0.468190461397171, Loss generator: 1.4690778255462646\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 249ms/step - d_loss: 0.3462 - g_loss: 1.7047\n",
      "Loss discriminator: 0.47400879859924316, Loss generator: 1.4517914056777954\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 249ms/step - d_loss: 0.3495 - g_loss: 1.6982\n",
      "Loss discriminator: 0.47968772053718567, Loss generator: 1.4348526000976562\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 248ms/step - d_loss: 0.3527 - g_loss: 1.6916\n",
      "Loss discriminator: 0.4849510192871094, Loss generator: 1.4191558361053467\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 248ms/step - d_loss: 0.3559 - g_loss: 1.6849\n",
      "Loss discriminator: 0.48977333307266235, Loss generator: 1.4047729969024658\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m58s\u001b[0m 248ms/step - d_loss: 0.3591 - g_loss: 1.6782\n",
      "Loss discriminator: 0.49407824873924255, Loss generator: 1.3908971548080444\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m53s\u001b[0m 248ms/step - d_loss: 0.3622 - g_loss: 1.6716\n",
      "Loss discriminator: 0.49829232692718506, Loss generator: 1.3773800134658813\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m48s\u001b[0m 248ms/step - d_loss: 0.3652 - g_loss: 1.6649\n",
      "Loss discriminator: 0.5019440650939941, Loss generator: 1.3647716045379639\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m43s\u001b[0m 248ms/step - d_loss: 0.3683 - g_loss: 1.6582\n",
      "Loss discriminator: 0.5056024193763733, Loss generator: 1.352500081062317\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m38s\u001b[0m 248ms/step - d_loss: 0.3712 - g_loss: 1.6516\n",
      "Loss discriminator: 0.5092839002609253, Loss generator: 1.3410933017730713\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m33s\u001b[0m 248ms/step - d_loss: 0.3741 - g_loss: 1.6450\n",
      "Loss discriminator: 0.5127667188644409, Loss generator: 1.3295930624008179\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m28s\u001b[0m 248ms/step - d_loss: 0.3770 - g_loss: 1.6385\n",
      "Loss discriminator: 0.5161935091018677, Loss generator: 1.3184173107147217\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m23s\u001b[0m 248ms/step - d_loss: 0.3798 - g_loss: 1.6320\n",
      "Loss discriminator: 0.5191113352775574, Loss generator: 1.3080083131790161\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 248ms/step - d_loss: 0.3826 - g_loss: 1.6256\n",
      "Loss discriminator: 0.5217502117156982, Loss generator: 1.2983852624893188\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 248ms/step - d_loss: 0.3853 - g_loss: 1.6192\n",
      "Loss discriminator: 0.5244311690330505, Loss generator: 1.289293646812439\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - d_loss: 0.3879 - g_loss: 1.6129\n",
      "Loss discriminator: 0.5269176959991455, Loss generator: 1.280318260192871\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 248ms/step - d_loss: 0.3905 - g_loss: 1.6066\n",
      "Loss discriminator: 0.528801441192627, Loss generator: 1.272472620010376\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 248ms/step - d_loss: 0.3923 - g_loss: 1.6023 - discriminator_loss: 0.5300 - generator_loss: 1.2676\n",
      "Epoch 9/20\n",
      "\n",
      "Loss discriminator: 0.6374733448028564, Loss generator: 0.8492954969406128\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:31\u001b[0m 253ms/step - d_loss: 0.6719 - g_loss: 0.8054\n",
      "Loss discriminator: 0.6719565391540527, Loss generator: 0.7997997999191284\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:24\u001b[0m 251ms/step - d_loss: 0.6701 - g_loss: 0.8081\n",
      "Loss discriminator: 0.6658959984779358, Loss generator: 0.81831294298172\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:17\u001b[0m 249ms/step - d_loss: 0.6682 - g_loss: 0.8109\n",
      "Loss discriminator: 0.6625095009803772, Loss generator: 0.81705242395401\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:12\u001b[0m 249ms/step - d_loss: 0.6669 - g_loss: 0.8120\n",
      "Loss discriminator: 0.6636240482330322, Loss generator: 0.8126795291900635\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07\u001b[0m 249ms/step - d_loss: 0.6662 - g_loss: 0.8130\n",
      "Loss discriminator: 0.6641035676002502, Loss generator: 0.81672602891922\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 249ms/step - d_loss: 0.6659 - g_loss: 0.8136\n",
      "Loss discriminator: 0.6652430295944214, Loss generator: 0.8167276382446289\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 249ms/step - d_loss: 0.6658 - g_loss: 0.8140\n",
      "Loss discriminator: 0.6641005277633667, Loss generator: 0.8164559006690979\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 249ms/step - d_loss: 0.6656 - g_loss: 0.8144\n",
      "Loss discriminator: 0.6646142601966858, Loss generator: 0.8167216777801514\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:47\u001b[0m 249ms/step - d_loss: 0.6653 - g_loss: 0.8146\n",
      "Loss discriminator: 0.6633056998252869, Loss generator: 0.8159836530685425\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:42\u001b[0m 249ms/step - d_loss: 0.6651 - g_loss: 0.8148\n",
      "Loss discriminator: 0.6625226736068726, Loss generator: 0.8150087594985962\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:37\u001b[0m 249ms/step - d_loss: 0.6649 - g_loss: 0.8150\n",
      "Loss discriminator: 0.6621735692024231, Loss generator: 0.8176069855690002\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 246ms/step - d_loss: 0.6646 - g_loss: 0.8152\n",
      "Loss discriminator: 0.6619723439216614, Loss generator: 0.8164166212081909\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 247ms/step - d_loss: 0.6644 - g_loss: 0.8152\n",
      "Loss discriminator: 0.6611186861991882, Loss generator: 0.8162860870361328\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 247ms/step - d_loss: 0.6642 - g_loss: 0.8153\n",
      "Loss discriminator: 0.6607937216758728, Loss generator: 0.8170482516288757\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 247ms/step - d_loss: 0.6639 - g_loss: 0.8155\n",
      "Loss discriminator: 0.6601951718330383, Loss generator: 0.8168898820877075\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:11\u001b[0m 247ms/step - d_loss: 0.6637 - g_loss: 0.8155\n",
      "Loss discriminator: 0.6593641042709351, Loss generator: 0.8164535164833069\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 247ms/step - d_loss: 0.6634 - g_loss: 0.8156\n",
      "Loss discriminator: 0.6588121056556702, Loss generator: 0.815933883190155\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 247ms/step - d_loss: 0.6631 - g_loss: 0.8156\n",
      "Loss discriminator: 0.658389151096344, Loss generator: 0.8153620362281799\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 247ms/step - d_loss: 0.6629 - g_loss: 0.8156\n",
      "Loss discriminator: 0.6579012870788574, Loss generator: 0.8151249885559082\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 247ms/step - d_loss: 0.6626 - g_loss: 0.8156\n",
      "Loss discriminator: 0.6576895713806152, Loss generator: 0.8147612810134888\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 248ms/step - d_loss: 0.6624 - g_loss: 0.8155\n",
      "Loss discriminator: 0.6581762433052063, Loss generator: 0.8140721917152405\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 248ms/step - d_loss: 0.6622 - g_loss: 0.8154\n",
      "Loss discriminator: 0.658056914806366, Loss generator: 0.8136387467384338\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 248ms/step - d_loss: 0.6620 - g_loss: 0.8153\n",
      "Loss discriminator: 0.6582366824150085, Loss generator: 0.8129687309265137\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 248ms/step - d_loss: 0.6619 - g_loss: 0.8152\n",
      "Loss discriminator: 0.6583766937255859, Loss generator: 0.8118807077407837\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 248ms/step - d_loss: 0.6617 - g_loss: 0.8151\n",
      "Loss discriminator: 0.6583884954452515, Loss generator: 0.8117877840995789\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 248ms/step - d_loss: 0.6616 - g_loss: 0.8149\n",
      "Loss discriminator: 0.6580172181129456, Loss generator: 0.8119971752166748\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 248ms/step - d_loss: 0.6614 - g_loss: 0.8148\n",
      "Loss discriminator: 0.6577700972557068, Loss generator: 0.812358558177948\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 248ms/step - d_loss: 0.6613 - g_loss: 0.8148\n",
      "Loss discriminator: 0.6577334403991699, Loss generator: 0.813554584980011\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 248ms/step - d_loss: 0.6612 - g_loss: 0.8147\n",
      "Loss discriminator: 0.6578645706176758, Loss generator: 0.8142533898353577\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 248ms/step - d_loss: 0.6611 - g_loss: 0.8147\n",
      "Loss discriminator: 0.6576542854309082, Loss generator: 0.8145667910575867\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 248ms/step - d_loss: 0.6610 - g_loss: 0.8147\n",
      "Loss discriminator: 0.6575394868850708, Loss generator: 0.8141501545906067\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 248ms/step - d_loss: 0.6609 - g_loss: 0.8147\n",
      "Loss discriminator: 0.6573249697685242, Loss generator: 0.8140708208084106\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 248ms/step - d_loss: 0.6607 - g_loss: 0.8147\n",
      "Loss discriminator: 0.6574116349220276, Loss generator: 0.814048707485199\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 249ms/step - d_loss: 0.6606 - g_loss: 0.8147\n",
      "Loss discriminator: 0.6570969820022583, Loss generator: 0.8137895464897156\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 247ms/step - d_loss: 0.6605 - g_loss: 0.8146\n",
      "Loss discriminator: 0.6570843458175659, Loss generator: 0.8131433725357056\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 247ms/step - d_loss: 0.6605 - g_loss: 0.8146\n",
      "Loss discriminator: 0.6577736139297485, Loss generator: 0.8125330805778503\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 247ms/step - d_loss: 0.6604 - g_loss: 0.8145\n",
      "Loss discriminator: 0.6578512191772461, Loss generator: 0.8118734359741211\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 247ms/step - d_loss: 0.6603 - g_loss: 0.8144\n",
      "Loss discriminator: 0.6579786539077759, Loss generator: 0.8113778829574585\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:17\u001b[0m 246ms/step - d_loss: 0.6603 - g_loss: 0.8144\n",
      "Loss discriminator: 0.658053457736969, Loss generator: 0.8112454414367676\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 246ms/step - d_loss: 0.6602 - g_loss: 0.8143\n",
      "Loss discriminator: 0.6582953929901123, Loss generator: 0.8107315897941589\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 244ms/step - d_loss: 0.6602 - g_loss: 0.8142\n",
      "Loss discriminator: 0.6585587859153748, Loss generator: 0.8106662631034851\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 243ms/step - d_loss: 0.6601 - g_loss: 0.8141\n",
      "Loss discriminator: 0.658774733543396, Loss generator: 0.8102296590805054\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m56s\u001b[0m 241ms/step - d_loss: 0.6601 - g_loss: 0.8140\n",
      "Loss discriminator: 0.6588857769966125, Loss generator: 0.8101386427879333\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m51s\u001b[0m 240ms/step - d_loss: 0.6601 - g_loss: 0.8139\n",
      "Loss discriminator: 0.6592373847961426, Loss generator: 0.8098858594894409\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m46s\u001b[0m 238ms/step - d_loss: 0.6601 - g_loss: 0.8138\n",
      "Loss discriminator: 0.6594362258911133, Loss generator: 0.8096473217010498\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41s\u001b[0m 237ms/step - d_loss: 0.6600 - g_loss: 0.8138\n",
      "Loss discriminator: 0.6591126322746277, Loss generator: 0.8103720545768738\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m36s\u001b[0m 237ms/step - d_loss: 0.6600 - g_loss: 0.8137\n",
      "Loss discriminator: 0.6595750451087952, Loss generator: 0.8111830353736877\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m31s\u001b[0m 236ms/step - d_loss: 0.6600 - g_loss: 0.8137\n",
      "Loss discriminator: 0.6599698662757874, Loss generator: 0.8132532835006714\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m26s\u001b[0m 235ms/step - d_loss: 0.6600 - g_loss: 0.8137\n",
      "Loss discriminator: 0.6591333150863647, Loss generator: 0.8183067440986633\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m21s\u001b[0m 234ms/step - d_loss: 0.6600 - g_loss: 0.8138\n",
      "Loss discriminator: 0.6581425666809082, Loss generator: 0.8230397701263428\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m17s\u001b[0m 233ms/step - d_loss: 0.6599 - g_loss: 0.8141\n",
      "Loss discriminator: 0.6570190191268921, Loss generator: 0.8267331123352051\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m12s\u001b[0m 231ms/step - d_loss: 0.6599 - g_loss: 0.8143\n",
      "Loss discriminator: 0.6567690372467041, Loss generator: 0.8279005885124207\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 231ms/step - d_loss: 0.6598 - g_loss: 0.8146\n",
      "Loss discriminator: 0.6562262177467346, Loss generator: 0.8294065594673157\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - d_loss: 0.6597 - g_loss: 0.8149\n",
      "Loss discriminator: 0.6554970741271973, Loss generator: 0.8310175538063049\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 229ms/step - d_loss: 0.6597 - g_loss: 0.8151 - discriminator_loss: 0.6546 - generator_loss: 0.8322\n",
      "Epoch 10/20\n",
      "\n",
      "Loss discriminator: 0.5762307643890381, Loss generator: 0.8441349267959595\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 172ms/step - d_loss: 0.6112 - g_loss: 0.8889\n",
      "Loss discriminator: 0.6386739015579224, Loss generator: 0.8512349724769592\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:07\u001b[0m 178ms/step - d_loss: 0.6304 - g_loss: 0.8612\n",
      "Loss discriminator: 0.6560057997703552, Loss generator: 0.8240598440170288\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:04\u001b[0m 179ms/step - d_loss: 0.6399 - g_loss: 0.8486\n",
      "Loss discriminator: 0.6629287600517273, Loss generator: 0.8247307538986206\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 177ms/step - d_loss: 0.6462 - g_loss: 0.8413\n",
      "Loss discriminator: 0.6669820547103882, Loss generator: 0.8154932856559753\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 177ms/step - d_loss: 0.6504 - g_loss: 0.8353\n",
      "Loss discriminator: 0.6667429804801941, Loss generator: 0.8107744455337524\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 176ms/step - d_loss: 0.6533 - g_loss: 0.8310\n",
      "Loss discriminator: 0.6681267023086548, Loss generator: 0.8080562353134155\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 177ms/step - d_loss: 0.6555 - g_loss: 0.8276\n",
      "Loss discriminator: 0.6706638336181641, Loss generator: 0.8055257797241211\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 177ms/step - d_loss: 0.6574 - g_loss: 0.8246\n",
      "Loss discriminator: 0.6710007190704346, Loss generator: 0.8042057752609253\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:42\u001b[0m 177ms/step - d_loss: 0.6590 - g_loss: 0.8221\n",
      "Loss discriminator: 0.6726951003074646, Loss generator: 0.8008825778961182\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:38\u001b[0m 177ms/step - d_loss: 0.6604 - g_loss: 0.8198\n",
      "Loss discriminator: 0.6737030744552612, Loss generator: 0.7973074316978455\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 177ms/step - d_loss: 0.6617 - g_loss: 0.8176\n",
      "Loss discriminator: 0.6755274534225464, Loss generator: 0.7933558821678162\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 178ms/step - d_loss: 0.6629 - g_loss: 0.8155\n",
      "Loss discriminator: 0.6752977967262268, Loss generator: 0.7919928431510925\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 178ms/step - d_loss: 0.6638 - g_loss: 0.8136\n",
      "Loss discriminator: 0.6746801733970642, Loss generator: 0.7898533344268799\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 178ms/step - d_loss: 0.6646 - g_loss: 0.8119\n",
      "Loss discriminator: 0.6749523282051086, Loss generator: 0.790216863155365\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 178ms/step - d_loss: 0.6653 - g_loss: 0.8104\n",
      "Loss discriminator: 0.6754579544067383, Loss generator: 0.7889915108680725\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 179ms/step - d_loss: 0.6659 - g_loss: 0.8090\n",
      "Loss discriminator: 0.6753550171852112, Loss generator: 0.7876646518707275\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 179ms/step - d_loss: 0.6665 - g_loss: 0.8077\n",
      "Loss discriminator: 0.6752817630767822, Loss generator: 0.7879235148429871\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 182ms/step - d_loss: 0.6670 - g_loss: 0.8066\n",
      "Loss discriminator: 0.6756865978240967, Loss generator: 0.786649227142334\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 183ms/step - d_loss: 0.6674 - g_loss: 0.8056\n",
      "Loss discriminator: 0.675248920917511, Loss generator: 0.7869318127632141\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 183ms/step - d_loss: 0.6678 - g_loss: 0.8046\n",
      "Loss discriminator: 0.6752495169639587, Loss generator: 0.7864822745323181\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 185ms/step - d_loss: 0.6682 - g_loss: 0.8037\n",
      "Loss discriminator: 0.6755393743515015, Loss generator: 0.7845116257667542\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 187ms/step - d_loss: 0.6685 - g_loss: 0.8028\n",
      "Loss discriminator: 0.6751677989959717, Loss generator: 0.7845149636268616\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 187ms/step - d_loss: 0.6688 - g_loss: 0.8021\n",
      "Loss discriminator: 0.6751887798309326, Loss generator: 0.7852025628089905\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 189ms/step - d_loss: 0.6691 - g_loss: 0.8013\n",
      "Loss discriminator: 0.6753458976745605, Loss generator: 0.7843208312988281\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 191ms/step - d_loss: 0.6693 - g_loss: 0.8006\n",
      "Loss discriminator: 0.6755213737487793, Loss generator: 0.7839729189872742\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 193ms/step - d_loss: 0.6696 - g_loss: 0.8000\n",
      "Loss discriminator: 0.6751827597618103, Loss generator: 0.7839071750640869\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 195ms/step - d_loss: 0.6698 - g_loss: 0.7994\n",
      "Loss discriminator: 0.6747894883155823, Loss generator: 0.7831076979637146\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 196ms/step - d_loss: 0.6699 - g_loss: 0.7988\n",
      "Loss discriminator: 0.6744053363800049, Loss generator: 0.7829621434211731\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 198ms/step - d_loss: 0.6701 - g_loss: 0.7983\n",
      "Loss discriminator: 0.6744288206100464, Loss generator: 0.7839615941047668\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 200ms/step - d_loss: 0.6702 - g_loss: 0.7978\n",
      "Loss discriminator: 0.6737325191497803, Loss generator: 0.7841649651527405\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 202ms/step - d_loss: 0.6703 - g_loss: 0.7974\n",
      "Loss discriminator: 0.6738142371177673, Loss generator: 0.784948468208313\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 203ms/step - d_loss: 0.6704 - g_loss: 0.7970\n",
      "Loss discriminator: 0.6738694310188293, Loss generator: 0.786841630935669\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 202ms/step - d_loss: 0.6705 - g_loss: 0.7967\n",
      "Loss discriminator: 0.6732448935508728, Loss generator: 0.7891942858695984\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 201ms/step - d_loss: 0.6706 - g_loss: 0.7965\n",
      "Loss discriminator: 0.6742017865180969, Loss generator: 0.7919290065765381\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 200ms/step - d_loss: 0.6707 - g_loss: 0.7965\n",
      "Loss discriminator: 0.6715388894081116, Loss generator: 0.7978624701499939\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 200ms/step - d_loss: 0.6707 - g_loss: 0.7965\n",
      "Loss discriminator: 0.6717584133148193, Loss generator: 0.798172116279602\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 199ms/step - d_loss: 0.6708 - g_loss: 0.7966\n",
      "Loss discriminator: 0.6722167730331421, Loss generator: 0.7986430525779724\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 199ms/step - d_loss: 0.6708 - g_loss: 0.7966\n",
      "Loss discriminator: 0.6718664169311523, Loss generator: 0.7999167442321777\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 198ms/step - d_loss: 0.6708 - g_loss: 0.7967\n",
      "Loss discriminator: 0.6718156337738037, Loss generator: 0.800392746925354\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 197ms/step - d_loss: 0.6709 - g_loss: 0.7968\n",
      "Loss discriminator: 0.6719602942466736, Loss generator: 0.7996222972869873\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 197ms/step - d_loss: 0.6709 - g_loss: 0.7969\n",
      "Loss discriminator: 0.6724308729171753, Loss generator: 0.7990185618400574\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m49s\u001b[0m 196ms/step - d_loss: 0.6709 - g_loss: 0.7969\n",
      "Loss discriminator: 0.6727191805839539, Loss generator: 0.7981413006782532\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 195ms/step - d_loss: 0.6710 - g_loss: 0.7969\n",
      "Loss discriminator: 0.6730323433876038, Loss generator: 0.7970727682113647\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41s\u001b[0m 195ms/step - d_loss: 0.6710 - g_loss: 0.7969\n",
      "Loss discriminator: 0.6735090017318726, Loss generator: 0.7961971759796143\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m37s\u001b[0m 194ms/step - d_loss: 0.6711 - g_loss: 0.7969\n",
      "Loss discriminator: 0.6739245057106018, Loss generator: 0.7957206964492798\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m33s\u001b[0m 194ms/step - d_loss: 0.6711 - g_loss: 0.7969\n",
      "Loss discriminator: 0.6738895773887634, Loss generator: 0.7950341105461121\n",
      "\u001b[1m 940/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m29s\u001b[0m 194ms/step - d_loss: 0.6712 - g_loss: 0.7968\n",
      "Loss discriminator: 0.6741103529930115, Loss generator: 0.7940033078193665\n",
      "\u001b[1m 960/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - d_loss: 0.6713 - g_loss: 0.7968\n",
      "Loss discriminator: 0.6744746565818787, Loss generator: 0.7934699058532715\n",
      "\u001b[1m 980/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 193ms/step - d_loss: 0.6713 - g_loss: 0.7967\n",
      "Loss discriminator: 0.6747617125511169, Loss generator: 0.7924324870109558\n",
      "\u001b[1m1000/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m18s\u001b[0m 193ms/step - d_loss: 0.6714 - g_loss: 0.7966\n",
      "Loss discriminator: 0.6747581362724304, Loss generator: 0.7917538285255432\n",
      "\u001b[1m1020/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m14s\u001b[0m 193ms/step - d_loss: 0.6715 - g_loss: 0.7965\n",
      "Loss discriminator: 0.674858033657074, Loss generator: 0.7917696237564087\n",
      "\u001b[1m1040/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - d_loss: 0.6715 - g_loss: 0.7964\n",
      "Loss discriminator: 0.6749731302261353, Loss generator: 0.7909557819366455\n",
      "\u001b[1m1060/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - d_loss: 0.6716 - g_loss: 0.7963\n",
      "Loss discriminator: 0.6747801899909973, Loss generator: 0.7905796766281128\n",
      "\u001b[1m1080/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - d_loss: 0.6717 - g_loss: 0.7962\n",
      "Loss discriminator: 0.6747853755950928, Loss generator: 0.7907171845436096\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 192ms/step - d_loss: 0.6717 - g_loss: 0.7961 - discriminator_loss: 0.6745 - generator_loss: 0.7912\n",
      "Epoch 11/20\n",
      "\n",
      "Loss discriminator: 0.6453997492790222, Loss generator: 0.8396534323692322\n",
      "\u001b[1m  20/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 179ms/step - d_loss: 0.6764 - g_loss: 0.7590\n",
      "Loss discriminator: 0.6846216320991516, Loss generator: 0.7504454851150513\n",
      "\u001b[1m  40/1094\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:09\u001b[0m 180ms/step - d_loss: 0.6804 - g_loss: 0.7548\n",
      "Loss discriminator: 0.6834077835083008, Loss generator: 0.7556710839271545\n",
      "\u001b[1m  60/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:05\u001b[0m 179ms/step - d_loss: 0.6812 - g_loss: 0.7581\n",
      "Loss discriminator: 0.6805581450462341, Loss generator: 0.7704321146011353\n",
      "\u001b[1m  80/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01\u001b[0m 179ms/step - d_loss: 0.6816 - g_loss: 0.7604\n",
      "Loss discriminator: 0.68436598777771, Loss generator: 0.7642655372619629\n",
      "\u001b[1m 100/1094\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 179ms/step - d_loss: 0.6821 - g_loss: 0.7610\n",
      "Loss discriminator: 0.6860674619674683, Loss generator: 0.7619643211364746\n",
      "\u001b[1m 120/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 179ms/step - d_loss: 0.6827 - g_loss: 0.7618\n",
      "Loss discriminator: 0.6842849850654602, Loss generator: 0.7696263194084167\n",
      "\u001b[1m 140/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 179ms/step - d_loss: 0.6832 - g_loss: 0.7625\n",
      "Loss discriminator: 0.6877607107162476, Loss generator: 0.7623336315155029\n",
      "\u001b[1m 160/1094\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 179ms/step - d_loss: 0.6836 - g_loss: 0.7627\n",
      "Loss discriminator: 0.6863239407539368, Loss generator: 0.765286386013031\n",
      "\u001b[1m 180/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 179ms/step - d_loss: 0.6840 - g_loss: 0.7630\n",
      "Loss discriminator: 0.6881694197654724, Loss generator: 0.7666792869567871\n",
      "\u001b[1m 200/1094\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 179ms/step - d_loss: 0.6844 - g_loss: 0.7635\n",
      "Loss discriminator: 0.6884957551956177, Loss generator: 0.7682347893714905\n",
      "\u001b[1m 220/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 179ms/step - d_loss: 0.6849 - g_loss: 0.7638\n",
      "Loss discriminator: 0.6890564560890198, Loss generator: 0.7654225826263428\n",
      "\u001b[1m 240/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 179ms/step - d_loss: 0.6853 - g_loss: 0.7639\n",
      "Loss discriminator: 0.6916599869728088, Loss generator: 0.7656564116477966\n",
      "\u001b[1m 260/1094\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 179ms/step - d_loss: 0.6857 - g_loss: 0.7643\n",
      "Loss discriminator: 0.6883543729782104, Loss generator: 0.7731227874755859\n",
      "\u001b[1m 280/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 179ms/step - d_loss: 0.6860 - g_loss: 0.7649\n",
      "Loss discriminator: 0.6915395855903625, Loss generator: 0.7704443335533142\n",
      "\u001b[1m 300/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 179ms/step - d_loss: 0.6862 - g_loss: 0.7654\n",
      "Loss discriminator: 0.6886857151985168, Loss generator: 0.7744519114494324\n",
      "\u001b[1m 320/1094\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 179ms/step - d_loss: 0.6864 - g_loss: 0.7660\n",
      "Loss discriminator: 0.6895889043807983, Loss generator: 0.7771066427230835\n",
      "\u001b[1m 340/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 179ms/step - d_loss: 0.6865 - g_loss: 0.7669\n",
      "Loss discriminator: 0.687209963798523, Loss generator: 0.7822985053062439\n",
      "\u001b[1m 360/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 179ms/step - d_loss: 0.6866 - g_loss: 0.7677\n",
      "Loss discriminator: 0.6893748641014099, Loss generator: 0.7794235944747925\n",
      "\u001b[1m 380/1094\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 179ms/step - d_loss: 0.6867 - g_loss: 0.7682\n",
      "Loss discriminator: 0.6885210871696472, Loss generator: 0.7787622213363647\n",
      "\u001b[1m 400/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 179ms/step - d_loss: 0.6869 - g_loss: 0.7687\n",
      "Loss discriminator: 0.6899969577789307, Loss generator: 0.7775147557258606\n",
      "\u001b[1m 420/1094\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 179ms/step - d_loss: 0.6870 - g_loss: 0.7692\n",
      "Loss discriminator: 0.6890524625778198, Loss generator: 0.7786447405815125\n",
      "\u001b[1m 440/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 179ms/step - d_loss: 0.6871 - g_loss: 0.7695\n",
      "Loss discriminator: 0.6911745071411133, Loss generator: 0.7747625708580017\n",
      "\u001b[1m 460/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 179ms/step - d_loss: 0.6873 - g_loss: 0.7698\n",
      "Loss discriminator: 0.691287636756897, Loss generator: 0.7736821174621582\n",
      "\u001b[1m 480/1094\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 179ms/step - d_loss: 0.6875 - g_loss: 0.7699\n",
      "Loss discriminator: 0.6919057369232178, Loss generator: 0.7738056182861328\n",
      "\u001b[1m 500/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 179ms/step - d_loss: 0.6877 - g_loss: 0.7701\n",
      "Loss discriminator: 0.6918022036552429, Loss generator: 0.7730696201324463\n",
      "\u001b[1m 520/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 179ms/step - d_loss: 0.6878 - g_loss: 0.7701\n",
      "Loss discriminator: 0.6924338936805725, Loss generator: 0.7711533904075623\n",
      "\u001b[1m 540/1094\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 179ms/step - d_loss: 0.6880 - g_loss: 0.7702\n",
      "Loss discriminator: 0.692543625831604, Loss generator: 0.7706300020217896\n",
      "\u001b[1m 560/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 180ms/step - d_loss: 0.6882 - g_loss: 0.7702\n",
      "Loss discriminator: 0.6929494142532349, Loss generator: 0.7708814144134521\n",
      "\u001b[1m 580/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 180ms/step - d_loss: 0.6883 - g_loss: 0.7702\n",
      "Loss discriminator: 0.6930155158042908, Loss generator: 0.7697874903678894\n",
      "\u001b[1m 600/1094\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 181ms/step - d_loss: 0.6885 - g_loss: 0.7702\n",
      "Loss discriminator: 0.6933258771896362, Loss generator: 0.7687411904335022\n",
      "\u001b[1m 620/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 181ms/step - d_loss: 0.6886 - g_loss: 0.7701\n",
      "Loss discriminator: 0.6934917569160461, Loss generator: 0.7682282328605652\n",
      "\u001b[1m 640/1094\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 181ms/step - d_loss: 0.6888 - g_loss: 0.7701\n",
      "Loss discriminator: 0.6932643055915833, Loss generator: 0.7687932252883911\n",
      "\u001b[1m 660/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 182ms/step - d_loss: 0.6889 - g_loss: 0.7700\n",
      "Loss discriminator: 0.6938364505767822, Loss generator: 0.7675567269325256\n",
      "\u001b[1m 680/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 182ms/step - d_loss: 0.6891 - g_loss: 0.7699\n",
      "Loss discriminator: 0.6941229701042175, Loss generator: 0.7662006616592407\n",
      "\u001b[1m 700/1094\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 182ms/step - d_loss: 0.6892 - g_loss: 0.7698\n",
      "Loss discriminator: 0.694209098815918, Loss generator: 0.7657670974731445\n",
      "\u001b[1m 720/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 182ms/step - d_loss: 0.6894 - g_loss: 0.7697\n",
      "Loss discriminator: 0.6946489214897156, Loss generator: 0.7660044431686401\n",
      "\u001b[1m 740/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 182ms/step - d_loss: 0.6895 - g_loss: 0.7696\n",
      "Loss discriminator: 0.6949443221092224, Loss generator: 0.7653155326843262\n",
      "\u001b[1m 760/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 182ms/step - d_loss: 0.6897 - g_loss: 0.7694\n",
      "Loss discriminator: 0.6951897144317627, Loss generator: 0.7640241384506226\n",
      "\u001b[1m 780/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 183ms/step - d_loss: 0.6898 - g_loss: 0.7693\n",
      "Loss discriminator: 0.695849597454071, Loss generator: 0.7632535099983215\n",
      "\u001b[1m 800/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 183ms/step - d_loss: 0.6900 - g_loss: 0.7692\n",
      "Loss discriminator: 0.6952903270721436, Loss generator: 0.764620304107666\n",
      "\u001b[1m 820/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 183ms/step - d_loss: 0.6901 - g_loss: 0.7691\n",
      "Loss discriminator: 0.695469856262207, Loss generator: 0.7641833424568176\n",
      "\u001b[1m 840/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - d_loss: 0.6902 - g_loss: 0.7689\n",
      "Loss discriminator: 0.6956576704978943, Loss generator: 0.7634694576263428\n",
      "\u001b[1m 860/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m42s\u001b[0m 183ms/step - d_loss: 0.6903 - g_loss: 0.7688\n",
      "Loss discriminator: 0.6956691145896912, Loss generator: 0.7631263732910156\n",
      "\u001b[1m 880/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m39s\u001b[0m 183ms/step - d_loss: 0.6905 - g_loss: 0.7687\n",
      "Loss discriminator: 0.6960360407829285, Loss generator: 0.7625429034233093\n",
      "\u001b[1m 900/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m35s\u001b[0m 183ms/step - d_loss: 0.6906 - g_loss: 0.7685\n",
      "Loss discriminator: 0.6957592964172363, Loss generator: 0.7626656889915466\n",
      "\u001b[1m 920/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 183ms/step - d_loss: 0.6907 - g_loss: 0.7684\n",
      "Loss discriminator: 0.6958786249160767, Loss generator: 0.7618532776832581\n",
      "\u001b[1m 929/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 183ms/step - d_loss: 0.6908 - g_loss: 0.7683"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m cond_gan \u001b[38;5;241m=\u001b[39m ConditionalGAN(\n\u001b[1;32m      4\u001b[0m     discriminator\u001b[38;5;241m=\u001b[39mdiscriminator, generator\u001b[38;5;241m=\u001b[39mgenerator, latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m cond_gan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      7\u001b[0m     d_optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m), \u001b[38;5;66;03m#(learning_rate=0.0003)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     g_optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0002\u001b[39m),\n\u001b[1;32m      9\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mcond_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/PhD_1/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks_list = [outs2()]\n",
    "\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001), #(learning_rate=0.0003)\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=20, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    }
   ],
   "source": [
    "# We first extract the trained generator from our Conditional GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = keras.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = ops.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = ops.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = ops.cast(first_label, \"float32\")\n",
    "    second_label = ops.cast(second_label, \"float32\")\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = ops.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = ops.cast(percent_second_label, \"float32\")\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = ops.concatenate([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 0  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 9  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/gif;base64,R0lGODlhYABgAIEAAAAAAAAAAAAAAAAAACH5BABYAgAALAAAAABgAGAAAAicAAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKHEmypMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUq0qNGjSJMqXcq0qdOnUKNKnUq1qtWrWLNq3cq1q9evYMOKHUu2rNmzaNOqXcu2rdu3cOPKnUu3rt27ePPq3cu3r9+/gAMLHky4sOHDJAMCACH5BAFkAHMALBYAAAAVAA8AhgAAAAEBAQICAgMDAwQEBAUFBQYGBggICAkJCQoKCgwMDA0NDQ4ODhAQEBQUFBUVFRcXFxgYGBwcHB4eHh8fHyUlJSgoKCwsLC8vLzIyMjMzMzQ0NDY2Njk5OTo6Ojw8PD4+PkBAQEVFRUhISElJSUpKSk1NTU5OTk9PT1BQUFJSUlNTU1VVVVpaWltbW1xcXF9fX2NjY2dnZ2hoaGlpaW9vb3d3d3x8fH9/f4KCgoSEhIWFhYaGhoeHh4yMjI6Ojo+Pj5CQkJGRkZOTk5aWlpqampycnJ2dnZ6enqCgoKWlpampqaqqqrGxsbKysrW1tbm5ucLCwsTExMnJycrKyszMzM7Ozs/Pz9DQ0NLS0tbW1tfX19nZ2dra2tzc3N7e3t/f3+Li4uTk5OXl5ejo6Orq6uvr6+zs7O3t7fDw8PLy8vPz8/T09Pb29vj4+Pr6+vv7+/z8/P///wAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj1AOcInONBxxU5CBPK4QJExMCHBA0qTMjQ4cABDipwkJGky0SEYZbU6GABgoEDGFjcSCKFzEc5aKYoyeFiwwIFJHZE6UKmzUs3ZbxQ+aHiAYMUQ7SUUfMmDpszYqJKFQPmSAsICDjECNLEyhk2W6AYKUK2LBEaHxoQkKChhA0mX85A4bEChd27JzhQODAnwAACIHpgEWNkRYICiBMXGCBgDoEIF0LUUOLFzBMcIzJMSABR4IEML3gsmVJmTRYnQmaAcNB5zgITPqqEQeMGTpoxXZDAoND6dWwuwINz0c278+fQQJIrB6KadefHkUVIny5CM+fOAQEAIfkEAcgAAQAsFgAAABUADwCBAAAAAAAAAAAAAAAACDMAAwgMAKCgwYMGByokiLAhAIUOI0qcSLGixYsYM1JkqJHjxoUeJ4IMKXHkRZMWUVYcGRAAOw==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = ops.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_images[:, :, :, 0], fps=1)\n",
    "embed.embed_file(\"animation.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
